{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "81f04853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "7b48f6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.common.output import ContextIO, ExtendedDatasetIO, InferredIO\n",
    "from scripts.common.schemas import ContextSymbolSchema, ExtendedTypeCollectionSchema, InferredSchema\n",
    "from scripts.common.schemas import TypeCollectionCategory, ContextCategory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "3fbc71dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import pandas as pd\n",
    "from pandera import typing as pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "39904488",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "from scripts.infer.structure import DatasetFolderStructure\n",
    "\n",
    "dataset = DatasetFolderStructure(pathlib.Path(\n",
    "    \"/nfs/data/students/bsparks/mdti4py-dataset-pool/cdt4py\"\n",
    "))\n",
    "ARTIFACT_ROOT = pathlib.Path(\"~/mdti4py/datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "2eba8ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_inference_artifacts(tool: str, task: TypeCollectionCategory | str) -> pd.DataFrame:\n",
    "    artifacts = []\n",
    "    for project in tqdm.tqdm(dataset.test_set(), desc=f\"Loading inference artifacts for {tool} @ {task}\"):\n",
    "        try:\n",
    "            artifacts.append(\n",
    "                InferredIO(artifact_root=ARTIFACT_ROOT, dataset=dataset, repository=project, tool_name=tool, task=task).read()\n",
    "                .assign(repository=str(dataset.author_repo(project)))\n",
    "                .replace(\"...\", pd.NA)\n",
    "                .drop_duplicates(subset=[\"repository\", ContextSymbolSchema.file, ContextSymbolSchema.category, ContextSymbolSchema.qname_ssa], keep=False)\n",
    "            )\n",
    "        except FileNotFoundError:\n",
    "            continue\n",
    "    return pd.concat(artifacts, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "6b0a5e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading context vectors: 100%|███████████████████████████████████████████████████| 1551/1551 [00:10<00:00, 154.12it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>category</th>\n",
       "      <th>qname</th>\n",
       "      <th>loop</th>\n",
       "      <th>reassigned</th>\n",
       "      <th>nested</th>\n",
       "      <th>flow_control</th>\n",
       "      <th>qname_ssa</th>\n",
       "      <th>repository</th>\n",
       "      <th>callable_return</th>\n",
       "      <th>callable_parameter</th>\n",
       "      <th>single_target_assign</th>\n",
       "      <th>ann_assign</th>\n",
       "      <th>aug_assign</th>\n",
       "      <th>multi_target_assign</th>\n",
       "      <th>instance_attribute</th>\n",
       "      <th>for_target</th>\n",
       "      <th>with_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>db.py</td>\n",
       "      <td>VARIABLE</td>\n",
       "      <td>FScore</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>FScoreλ1</td>\n",
       "      <td>0hoo__flask-snowball</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>db.py</td>\n",
       "      <td>VARIABLE</td>\n",
       "      <td>YearStat</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>YearStatλ1</td>\n",
       "      <td>0hoo__flask-snowball</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>db.py</td>\n",
       "      <td>VARIABLE</td>\n",
       "      <td>Quarter</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Quarterλ1</td>\n",
       "      <td>0hoo__flask-snowball</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>db.py</td>\n",
       "      <td>VARIABLE</td>\n",
       "      <td>FilterOption</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>FilterOptionλ1</td>\n",
       "      <td>0hoo__flask-snowball</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>db.py</td>\n",
       "      <td>VARIABLE</td>\n",
       "      <td>RankOption</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>RankOptionλ1</td>\n",
       "      <td>0hoo__flask-snowball</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>db.py</td>\n",
       "      <td>VARIABLE</td>\n",
       "      <td>YEAR_STAT</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>YEAR_STATλ1</td>\n",
       "      <td>0hoo__flask-snowball</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>db.py</td>\n",
       "      <td>VARIABLE</td>\n",
       "      <td>YEAR_FSCORE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>YEAR_FSCOREλ1</td>\n",
       "      <td>0hoo__flask-snowball</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>db.py</td>\n",
       "      <td>VARIABLE</td>\n",
       "      <td>client</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>clientλ1</td>\n",
       "      <td>0hoo__flask-snowball</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>db.py</td>\n",
       "      <td>VARIABLE</td>\n",
       "      <td>db</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dbλ1</td>\n",
       "      <td>0hoo__flask-snowball</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>db.py</td>\n",
       "      <td>VARIABLE</td>\n",
       "      <td>DIVIDEND_TAX_RATE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>DIVIDEND_TAX_RATEλ1</td>\n",
       "      <td>0hoo__flask-snowball</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>db.py</td>\n",
       "      <td>VARIABLE</td>\n",
       "      <td>FUTURE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>FUTUREλ1</td>\n",
       "      <td>0hoo__flask-snowball</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>db.py</td>\n",
       "      <td>VARIABLE</td>\n",
       "      <td>TARGET_RATE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>TARGET_RATEλ1</td>\n",
       "      <td>0hoo__flask-snowball</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>db.py</td>\n",
       "      <td>VARIABLE</td>\n",
       "      <td>THIS_YEAR</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>THIS_YEARλ1</td>\n",
       "      <td>0hoo__flask-snowball</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>db.py</td>\n",
       "      <td>VARIABLE</td>\n",
       "      <td>LAST_YEAR</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>LAST_YEARλ1</td>\n",
       "      <td>0hoo__flask-snowball</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>db.py</td>\n",
       "      <td>VARIABLE</td>\n",
       "      <td>available_rank_options</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>available_rank_optionsλ1</td>\n",
       "      <td>0hoo__flask-snowball</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>db.py</td>\n",
       "      <td>VARIABLE</td>\n",
       "      <td>available_filter_options</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>available_filter_optionsλ1</td>\n",
       "      <td>0hoo__flask-snowball</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>db.py</td>\n",
       "      <td>CALLABLE_RETURN</td>\n",
       "      <td>Filter.filter_options</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Filter.filter_options</td>\n",
       "      <td>0hoo__flask-snowball</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>db.py</td>\n",
       "      <td>CALLABLE_PARAMETER</td>\n",
       "      <td>Filter.filter_options.self</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Filter.filter_options.self</td>\n",
       "      <td>0hoo__flask-snowball</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>db.py</td>\n",
       "      <td>CALLABLE_RETURN</td>\n",
       "      <td>Filter.dict_filter_options</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Filter.dict_filter_options</td>\n",
       "      <td>0hoo__flask-snowball</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>db.py</td>\n",
       "      <td>CALLABLE_PARAMETER</td>\n",
       "      <td>Filter.dict_filter_options.self</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Filter.dict_filter_options.self</td>\n",
       "      <td>0hoo__flask-snowball</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     file            category                            qname loop  \\\n",
       "0   db.py            VARIABLE                           FScore    0   \n",
       "1   db.py            VARIABLE                         YearStat    0   \n",
       "2   db.py            VARIABLE                          Quarter    0   \n",
       "3   db.py            VARIABLE                     FilterOption    0   \n",
       "4   db.py            VARIABLE                       RankOption    0   \n",
       "5   db.py            VARIABLE                        YEAR_STAT    0   \n",
       "6   db.py            VARIABLE                      YEAR_FSCORE    0   \n",
       "7   db.py            VARIABLE                           client    0   \n",
       "8   db.py            VARIABLE                               db    0   \n",
       "9   db.py            VARIABLE                DIVIDEND_TAX_RATE    0   \n",
       "10  db.py            VARIABLE                           FUTURE    0   \n",
       "11  db.py            VARIABLE                      TARGET_RATE    0   \n",
       "12  db.py            VARIABLE                        THIS_YEAR    0   \n",
       "13  db.py            VARIABLE                        LAST_YEAR    0   \n",
       "14  db.py            VARIABLE           available_rank_options    0   \n",
       "15  db.py            VARIABLE         available_filter_options    0   \n",
       "16  db.py     CALLABLE_RETURN            Filter.filter_options    0   \n",
       "17  db.py  CALLABLE_PARAMETER       Filter.filter_options.self    0   \n",
       "18  db.py     CALLABLE_RETURN       Filter.dict_filter_options    0   \n",
       "19  db.py  CALLABLE_PARAMETER  Filter.dict_filter_options.self    0   \n",
       "\n",
       "   reassigned nested flow_control                        qname_ssa  \\\n",
       "0           0      0            0                         FScoreλ1   \n",
       "1           0      0            0                       YearStatλ1   \n",
       "2           0      0            0                        Quarterλ1   \n",
       "3           0      0            0                   FilterOptionλ1   \n",
       "4           0      0            0                     RankOptionλ1   \n",
       "5           0      0            0                      YEAR_STATλ1   \n",
       "6           0      0            0                    YEAR_FSCOREλ1   \n",
       "7           0      0            0                         clientλ1   \n",
       "8           0      0            0                             dbλ1   \n",
       "9           0      0            0              DIVIDEND_TAX_RATEλ1   \n",
       "10          0      0            0                         FUTUREλ1   \n",
       "11          0      0            0                    TARGET_RATEλ1   \n",
       "12          0      0            0                      THIS_YEARλ1   \n",
       "13          0      0            0                      LAST_YEARλ1   \n",
       "14          0      0            0         available_rank_optionsλ1   \n",
       "15          0      0            0       available_filter_optionsλ1   \n",
       "16          0      0            0            Filter.filter_options   \n",
       "17          0      0            0       Filter.filter_options.self   \n",
       "18          0      0            0       Filter.dict_filter_options   \n",
       "19          0      0            0  Filter.dict_filter_options.self   \n",
       "\n",
       "              repository  callable_return  callable_parameter  \\\n",
       "0   0hoo__flask-snowball                0                   0   \n",
       "1   0hoo__flask-snowball                0                   0   \n",
       "2   0hoo__flask-snowball                0                   0   \n",
       "3   0hoo__flask-snowball                0                   0   \n",
       "4   0hoo__flask-snowball                0                   0   \n",
       "5   0hoo__flask-snowball                0                   0   \n",
       "6   0hoo__flask-snowball                0                   0   \n",
       "7   0hoo__flask-snowball                0                   0   \n",
       "8   0hoo__flask-snowball                0                   0   \n",
       "9   0hoo__flask-snowball                0                   0   \n",
       "10  0hoo__flask-snowball                0                   0   \n",
       "11  0hoo__flask-snowball                0                   0   \n",
       "12  0hoo__flask-snowball                0                   0   \n",
       "13  0hoo__flask-snowball                0                   0   \n",
       "14  0hoo__flask-snowball                0                   0   \n",
       "15  0hoo__flask-snowball                0                   0   \n",
       "16  0hoo__flask-snowball                1                   0   \n",
       "17  0hoo__flask-snowball                0                   1   \n",
       "18  0hoo__flask-snowball                1                   0   \n",
       "19  0hoo__flask-snowball                0                   1   \n",
       "\n",
       "    single_target_assign  ann_assign  aug_assign  multi_target_assign  \\\n",
       "0                      1           0           0                    0   \n",
       "1                      1           0           0                    0   \n",
       "2                      1           0           0                    0   \n",
       "3                      1           0           0                    0   \n",
       "4                      1           0           0                    0   \n",
       "5                      1           0           0                    0   \n",
       "6                      1           0           0                    0   \n",
       "7                      1           0           0                    0   \n",
       "8                      1           0           0                    0   \n",
       "9                      1           0           0                    0   \n",
       "10                     1           0           0                    0   \n",
       "11                     1           0           0                    0   \n",
       "12                     1           0           0                    0   \n",
       "13                     1           0           0                    0   \n",
       "14                     1           0           0                    0   \n",
       "15                     1           0           0                    0   \n",
       "16                     0           0           0                    0   \n",
       "17                     0           0           0                    0   \n",
       "18                     0           0           0                    0   \n",
       "19                     0           0           0                    0   \n",
       "\n",
       "    instance_attribute  for_target  with_target  \n",
       "0                    0           0            0  \n",
       "1                    0           0            0  \n",
       "2                    0           0            0  \n",
       "3                    0           0            0  \n",
       "4                    0           0            0  \n",
       "5                    0           0            0  \n",
       "6                    0           0            0  \n",
       "7                    0           0            0  \n",
       "8                    0           0            0  \n",
       "9                    0           0            0  \n",
       "10                   0           0            0  \n",
       "11                   0           0            0  \n",
       "12                   0           0            0  \n",
       "13                   0           0            0  \n",
       "14                   0           0            0  \n",
       "15                   0           0            0  \n",
       "16                   0           0            0  \n",
       "17                   0           0            0  \n",
       "18                   0           0            0  \n",
       "19                   0           0            0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "context_artifacts = pd.concat([\n",
    "    ContextIO(artifact_root=ARTIFACT_ROOT, dataset=dataset, repository=project).read()\n",
    "        .assign(repository=str(dataset.author_repo(project)))\n",
    "        .drop_duplicates(subset=[\"repository\", ContextSymbolSchema.file, ContextSymbolSchema.category, ContextSymbolSchema.qname_ssa], keep=False)\n",
    "    for project in tqdm.tqdm(dataset.test_set(), desc=\"Loading context vectors\")\n",
    "], ignore_index=True)\n",
    "\n",
    "dummified_mapping = {\n",
    "    f\"context_category_{category.value}\": category.name.lower()\n",
    "    for category in ContextCategory\n",
    "}\n",
    "\n",
    "context_artifacts = pd.get_dummies(context_artifacts, columns=[ContextSymbolSchema.context_category], dtype=int).rename(columns=dummified_mapping) \\\n",
    "    .drop(columns=[\"builtin_source\", \"local_source\", \"import_source\"])\n",
    "display(context_artifacts.head(n=20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "213b9064",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading ground truths: 100%|█████████████████████████████████████████████████████| 1551/1551 [00:13<00:00, 117.34it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "extended_ground_truths = pd.concat([\n",
    "    ExtendedDatasetIO(artifact_root=ARTIFACT_ROOT, dataset=dataset, repository=project).read()\n",
    "        .assign(repository=str(dataset.author_repo(project)))\n",
    "        .drop_duplicates(subset=[\"repository\", ContextSymbolSchema.file, ContextSymbolSchema.category, ContextSymbolSchema.qname_ssa], keep=False)\n",
    "    for project in tqdm.tqdm(dataset.test_set(), desc=\"Loading ground truths\")\n",
    "], ignore_index=True).fillna(pd.NA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "69fe73b0-69c4-470c-ad89-3cc1a88af5a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1211154, 18)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1201979, 9)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(context_artifacts.shape)\n",
    "display(extended_ground_truths.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "02da25d3-2a78-46f6-ba03-de41920bcd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truths_with_context = pd.merge(\n",
    "    left=extended_ground_truths,\n",
    "    right=context_artifacts,\n",
    "    on=[\"repository\", ContextSymbolSchema.file, ContextSymbolSchema.category, ContextSymbolSchema.qname, ContextSymbolSchema.qname_ssa],\n",
    "    how=\"outer\",\n",
    "    indicator=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "c7d45787-2201-4828-9ef6-0a067d8ec8b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_merge\n",
       "both          0.991550\n",
       "right_only    0.008011\n",
       "left_only     0.000439\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(ground_truths_with_context[\"_merge\"].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "8c6c900c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truths_with_context = pd.merge(\n",
    "    left=extended_ground_truths,\n",
    "    right=context_artifacts,\n",
    "    on=[\"repository\", ContextSymbolSchema.file, ContextSymbolSchema.category, ContextSymbolSchema.qname_ssa],\n",
    "    how=\"inner\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "3f5aa089",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataclasses\n",
    "from scripts.dataset import normalisation\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class RegressionArtifacts:\n",
    "    predictions_made: pd.DataFrame\n",
    "    #matching_raw: pd.DataFrame\n",
    "    #matching_depth_limited: pd.DataFrame\n",
    "    #matching_adjusted: pd.DataFrame\n",
    "    #matching_base: pd.DataFrame\n",
    "\n",
    "def create_inputs_for_regression(tool: str, task: TypeCollectionCategory | str) -> RegressionArtifacts:\n",
    "    tqdm.tqdm.pandas()\n",
    "    inference = load_inference_artifacts(tool=tool, task=task)\n",
    "    inference_vs_ground_truth_with_context = pd.merge(\n",
    "        left=inference,\n",
    "        right=ground_truths_with_context,\n",
    "        on=[\"repository\", ContextSymbolSchema.file, ContextSymbolSchema.category, ContextSymbolSchema.qname_ssa],\n",
    "        how=\"inner\",\n",
    "        validate=\"1:1\"\n",
    "    )\n",
    "    \n",
    "    ### All samples\n",
    "    # Find where predictions were made\n",
    "    print(f\"=== {tool}/{task}: Scoring whether predictions were made ... === \")\n",
    "    predictions_made = inference_vs_ground_truth_with_context[InferredSchema.anno].notna()\n",
    "    predictions_made_df = inference_vs_ground_truth_with_context.assign(yscore=predictions_made).drop(columns=[\n",
    "        ExtendedTypeCollectionSchema.raw_anno, ExtendedTypeCollectionSchema.depth_limited_anno, \n",
    "        ExtendedTypeCollectionSchema.adjusted_anno, ExtendedTypeCollectionSchema.base_anno,\n",
    "    ])\n",
    "\n",
    "    # Merge Single Assign and AnnAssign together, as tools never get to see AnnAssign due to masking\n",
    "    predictions_made_df[\"single_target_assign\"] += predictions_made_df[\"ann_assign\"]\n",
    "    predictions_made_df = predictions_made_df.drop(columns=[\"ann_assign\"])\n",
    "    assert not (predictions_made_df[\"single_target_assign\"] > 1).any()\n",
    "    \n",
    "    \"\"\"\n",
    "    ### Only where predictions were made and we have a ground truth label\n",
    "    inference_vs_ground_truth_with_context = inference_vs_ground_truth_with_context[\n",
    "        inference_vs_ground_truth_with_context[InferredSchema.anno].notna() &\n",
    "        inference_vs_ground_truth_with_context[ExtendedTypeCollectionSchema.raw_anno].notna()\n",
    "    ]\n",
    "    \n",
    "    # Find where lightly processed annotations line up\n",
    "    print(f\"=== {tool}/{task}: Scoring where predictions match ground truths exactly ... ===\")\n",
    "    matching_raw = inference_vs_ground_truth_with_context[InferredSchema.anno] == inference_vs_ground_truth_with_context[ExtendedTypeCollectionSchema.raw_anno]\n",
    "    matching_raw_df = inference_vs_ground_truth_with_context.assign(yscore=matching_raw).drop(columns=[\n",
    "        ExtendedTypeCollectionSchema.depth_limited_anno, ExtendedTypeCollectionSchema.adjusted_anno, ExtendedTypeCollectionSchema.base_anno,\n",
    "    ])\n",
    "    \n",
    "    \n",
    "    # Apply depth limiting, as every work except TypeT5 has done\n",
    "    print(f\"=== {tool}/{task}: Scoring where depth limited predictions match depth limited ground truths ... ===\")\n",
    "    depth_limited_inferred = inference_vs_ground_truth_with_context[InferredSchema.anno].progress_apply(normalisation.to_limited)\n",
    "    matching_depth_limited = depth_limited_inferred == inference_vs_ground_truth_with_context[ExtendedTypeCollectionSchema.depth_limited_anno]\n",
    "    matching_depth_df = inference_vs_ground_truth_with_context.assign(inferred_depth_limited=depth_limited_inferred, yscore=matching_depth_limited).drop(columns=[\n",
    "        ExtendedTypeCollectionSchema.raw_anno, ExtendedTypeCollectionSchema.adjusted_anno, ExtendedTypeCollectionSchema.base_anno,\n",
    "    ])\n",
    "\n",
    "    \n",
    "    # Convert to adjusted annotations from depth limited annotations, without ground truth having typing.Any and None\n",
    "    print(f\"=== {tool}/{task}: Scoring where adjusted predictions match adjusted ground truths ... ===\")\n",
    "    print(f\"=== {tool}/{task}: Dropping Ground Truths with typing.Any, None ... ===\")\n",
    "    inference_vs_ground_truth_with_context = inference_vs_ground_truth_with_context[\n",
    "         ~inference_vs_ground_truth_with_context[ExtendedTypeCollectionSchema.raw_anno].isin([\"typing.Any\", \"Any\", \"None\"])\n",
    "    ]\n",
    "    \n",
    "    # Recalculate depth limited for shaping reasons\n",
    "    depth_limited_inferred = inference_vs_ground_truth_with_context[InferredSchema.anno].progress_apply(normalisation.to_limited)\n",
    "    adjusted_anno = depth_limited_inferred.progress_apply(normalisation.to_adjusted)\n",
    "    matching_adjusted = adjusted_anno == inference_vs_ground_truth_with_context[ExtendedTypeCollectionSchema.adjusted_anno]\n",
    "    matching_adjusted_df = inference_vs_ground_truth_with_context.assign(inferred_adjusted=adjusted_anno, yscore=matching_adjusted).drop(columns=[\n",
    "        ExtendedTypeCollectionSchema.raw_anno, ExtendedTypeCollectionSchema.depth_limited_anno, ExtendedTypeCollectionSchema.base_anno,\n",
    "    ])\n",
    "    \n",
    "    # Convert to base annotation to depth limited annotations, exclude none and any, as done in TypeT5\n",
    "    print(f\"{tool}/{task}: Scoring where base predictions match base ground truths ...\")\n",
    "    base_anno = depth_limited_inferred.progress_apply(normalisation.to_base)\n",
    "    matching_base = base_anno == inference_vs_ground_truth_with_context[ExtendedTypeCollectionSchema.base_anno]\n",
    "    matching_base_df = inference_vs_ground_truth_with_context.assign(inferred_base=base_anno, yscore=matching_base).drop(columns=[\n",
    "        ExtendedTypeCollectionSchema.raw_anno, ExtendedTypeCollectionSchema.depth_limited_anno, ExtendedTypeCollectionSchema.adjusted_anno,\n",
    "    ])\n",
    "    \n",
    "    print(\n",
    "        f\"{predictions_made_df.shape=}\", \n",
    "        f\"{matching_raw_df.shape=}\", \n",
    "        f\"{matching_depth_df.shape=}\", \n",
    "        f\"{matching_adjusted_df.shape=}\", \n",
    "        f\"{matching_base_df.shape=}\", \n",
    "        sep=\"\\n\"\n",
    "    )\"\"\"\n",
    "    print(f\"{predictions_made_df.shape=}\")\n",
    "    \n",
    "    return RegressionArtifacts(\n",
    "        predictions_made=predictions_made_df,\n",
    "    )\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "eaf644e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_SET = list(dummified_mapping.values()) + [\n",
    "    ContextSymbolSchema.loop, ContextSymbolSchema.reassigned, ContextSymbolSchema.nested, ContextSymbolSchema.flow_control\n",
    "]\n",
    "FEATURE_SET.remove(\"ann_assign\")\n",
    "\n",
    "FEATURE_SET_WITH_SCORE = FEATURE_SET + [\"yscore\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "064c3ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "from sklearn import linear_model\n",
    "\n",
    "def regression(features, X, y) -> pd.DataFrame:\n",
    "    lr = linear_model.LogisticRegression(\n",
    "        penalty=\"l2\",\n",
    "        solver=\"newton-cholesky\",\n",
    "    )\n",
    "    lr.fit(X, y)\n",
    "\n",
    "    feature2coef = dict(zip(features, lr.coef_[0]))\n",
    "    pprint.pprint(feature2coef)\n",
    "\n",
    "    return pd.DataFrame({\n",
    "        feature: [coef] for feature, coef in feature2coef.items()\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "f06f9cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_made_regression(artifacts: RegressionArtifacts) -> pd.DataFrame:\n",
    "    debug_feature_set = FEATURE_SET_WITH_SCORE + [InferredSchema.file, InferredSchema.qname, InferredSchema.anno]\n",
    "    \n",
    "    df = artifacts.predictions_made[debug_feature_set]\n",
    "    # print(df.head(n=20).to_string(), df.dtypes, sep=\"\\n\")\n",
    "    \n",
    "    df = artifacts.predictions_made[FEATURE_SET_WITH_SCORE].astype(int)\n",
    "    X, y = df[FEATURE_SET].to_numpy(), df[\"yscore\"]\n",
    "    \n",
    "    return regression(FEATURE_SET, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "400d3d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matching_raw_regression(artifacts: RegressionArtifacts) -> None:\n",
    "    debug_feature_set = FEATURE_SET_WITH_SCORE + [InferredSchema.file, ExtendedTypeCollectionSchema.raw_anno, InferredSchema.anno]\n",
    "\n",
    "    \n",
    "    df = artifacts.matching_raw[debug_feature_set]\n",
    "    # print(df.head(n=20).to_string(), df.dtypes, sep=\"\\n\")\n",
    "    \n",
    "    df = artifacts.matching_raw[FEATURE_SET_WITH_SCORE].astype(int)\n",
    "    X, y = df[FEATURE_SET].to_numpy(), df[\"yscore\"]\n",
    "    \n",
    "    regression(FEATURE_SET, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6947f6",
   "metadata": {},
   "source": [
    "# TypeT5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "af628c99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading inference artifacts for TypeT5TopN1 @ all: 100%|█████████████████████████| 1551/1551 [00:10<00:00, 150.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TypeT5TopN1/all: Scoring whether predictions were made ... === \n",
      "predictions_made_df.shape=(1174845, 23)\n"
     ]
    }
   ],
   "source": [
    "type_t5 = create_inputs_for_regression(tool=\"TypeT5TopN1\", task=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "e562e6da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'aug_assign': -2.3865499353745774,\n",
      " 'callable_parameter': 3.1817187701217877,\n",
      " 'callable_return': 4.795902008201029,\n",
      " 'flow_control': -0.8457234026173808,\n",
      " 'for_target': -2.8753578247329923,\n",
      " 'instance_attribute': 4.143336029232435,\n",
      " 'loop': -1.348879839882603,\n",
      " 'multi_target_assign': -3.9626509130177143,\n",
      " 'nested': -2.52800969456345,\n",
      " 'reassigned': -1.5677212407647376,\n",
      " 'single_target_assign': 1.0716510583923338,\n",
      " 'with_target': -3.9680491925944796}\n"
     ]
    }
   ],
   "source": [
    "typet5_coeffs = prediction_made_regression(artifacts=type_t5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3e454e-54c8-4e9c-b861-d0172885536f",
   "metadata": {},
   "source": [
    "# Type4Py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "a10c02a3-8f9f-4bca-8fe4-ffaa3e32795b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading inference artifacts for type4pyN1 @ all: 100%|███████████████████████████| 1551/1551 [00:10<00:00, 146.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== type4pyN1/all: Scoring whether predictions were made ... === \n",
      "predictions_made_df.shape=(1201447, 23)\n"
     ]
    }
   ],
   "source": [
    "type4py = create_inputs_for_regression(tool=\"type4pyN1\", task=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "d51ce3e8-3cb3-408e-a51b-20ff02f29b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'aug_assign': -3.5718594611275853,\n",
      " 'callable_parameter': 2.859435512696114,\n",
      " 'callable_return': 2.21768352277813,\n",
      " 'flow_control': -0.8040044663940237,\n",
      " 'for_target': -4.416799564486529,\n",
      " 'instance_attribute': 6.777593478654966,\n",
      " 'loop': 0.3284316105886974,\n",
      " 'multi_target_assign': -3.9084851360610626,\n",
      " 'nested': 0.23722451037931022,\n",
      " 'reassigned': -1.378490218220115,\n",
      " 'single_target_assign': 3.3731944074120177,\n",
      " 'with_target': -3.330762761017993}\n"
     ]
    }
   ],
   "source": [
    "type4py_coeffs = prediction_made_regression(artifacts=type4py)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaaee2d1-3688-4fe7-9530-64ad75b3e5d1",
   "metadata": {},
   "source": [
    "# Typilus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "47948b03-1b70-46c3-82b5-6d245de7d6ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading inference artifacts for typilusN1 @ all: 100%|███████████████████████████| 1551/1551 [00:10<00:00, 145.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== typilusN1/all: Scoring whether predictions were made ... === \n",
      "predictions_made_df.shape=(1201399, 23)\n"
     ]
    }
   ],
   "source": [
    "typilus = create_inputs_for_regression(tool=\"typilusN1\", task=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "0e07d49e-e101-4b93-87bf-fe5aead83766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'aug_assign': -3.0013803543677233,\n",
      " 'callable_parameter': 2.7062961454900387,\n",
      " 'callable_return': 3.8744674952626097,\n",
      " 'flow_control': -1.084221136862369,\n",
      " 'for_target': -5.347908255707595,\n",
      " 'instance_attribute': 6.1509188142034565,\n",
      " 'loop': 1.0624195615165506,\n",
      " 'multi_target_assign': -4.281213825044946,\n",
      " 'nested': -0.4638672598142172,\n",
      " 'reassigned': -4.436911382588121,\n",
      " 'single_target_assign': 3.4890108030994256,\n",
      " 'with_target': -3.590190824001904}\n"
     ]
    }
   ],
   "source": [
    "typilus_coeffs = prediction_made_regression(artifacts=typilus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed29ef8e-0bb2-4208-83ed-fe8b93df4335",
   "metadata": {},
   "source": [
    "# HiTyper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "c9200395-14e1-493a-8aa3-3e1ec7447243",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading inference artifacts for HiTyperNoML @ all: 100%|█████████████████████████| 1551/1551 [00:10<00:00, 144.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== HiTyperNoML/all: Scoring whether predictions were made ... === \n",
      "predictions_made_df.shape=(1193685, 23)\n"
     ]
    }
   ],
   "source": [
    "hityper = create_inputs_for_regression(tool=\"HiTyperNoML\", task=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "dd7b7a40-9a29-428a-86e9-8b34fd7ec89e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'aug_assign': -2.9407768110538197,\n",
      " 'callable_parameter': 3.207847223613874,\n",
      " 'callable_return': 5.995557788516962,\n",
      " 'flow_control': 0.44832911075975496,\n",
      " 'for_target': -2.602917028528865,\n",
      " 'instance_attribute': -2.685296190594103,\n",
      " 'loop': -0.1721123272411888,\n",
      " 'multi_target_assign': -2.6791575291484566,\n",
      " 'nested': -2.547257201116788,\n",
      " 'reassigned': 0.39555761429452607,\n",
      " 'single_target_assign': 4.38902416281002,\n",
      " 'with_target': -2.6842816168544004}\n"
     ]
    }
   ],
   "source": [
    "hityper_coeffs = prediction_made_regression(artifacts=hityper)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2908f94a-da3f-44af-b9f3-e487974a7c2c",
   "metadata": {},
   "source": [
    "# Accumulate Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "f036e210-a551-4ae8-a292-bfa579c81ee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>callable_return</th>\n",
       "      <th>callable_parameter</th>\n",
       "      <th>single_target_assign</th>\n",
       "      <th>aug_assign</th>\n",
       "      <th>multi_target_assign</th>\n",
       "      <th>instance_attribute</th>\n",
       "      <th>for_target</th>\n",
       "      <th>with_target</th>\n",
       "      <th>loop</th>\n",
       "      <th>reassigned</th>\n",
       "      <th>nested</th>\n",
       "      <th>flow_control</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Typilus</th>\n",
       "      <td>3.874467</td>\n",
       "      <td>2.706296</td>\n",
       "      <td>3.489011</td>\n",
       "      <td>-3.001380</td>\n",
       "      <td>-4.281214</td>\n",
       "      <td>6.150919</td>\n",
       "      <td>-5.347908</td>\n",
       "      <td>-3.590191</td>\n",
       "      <td>1.062420</td>\n",
       "      <td>-4.436911</td>\n",
       "      <td>-0.463867</td>\n",
       "      <td>-1.084221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Type4Py</th>\n",
       "      <td>2.217684</td>\n",
       "      <td>2.859436</td>\n",
       "      <td>3.373194</td>\n",
       "      <td>-3.571859</td>\n",
       "      <td>-3.908485</td>\n",
       "      <td>6.777593</td>\n",
       "      <td>-4.416800</td>\n",
       "      <td>-3.330763</td>\n",
       "      <td>0.328432</td>\n",
       "      <td>-1.378490</td>\n",
       "      <td>0.237225</td>\n",
       "      <td>-0.804004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TypeT5</th>\n",
       "      <td>4.795902</td>\n",
       "      <td>3.181719</td>\n",
       "      <td>1.071651</td>\n",
       "      <td>-2.386550</td>\n",
       "      <td>-3.962651</td>\n",
       "      <td>4.143336</td>\n",
       "      <td>-2.875358</td>\n",
       "      <td>-3.968049</td>\n",
       "      <td>-1.348880</td>\n",
       "      <td>-1.567721</td>\n",
       "      <td>-2.528010</td>\n",
       "      <td>-0.845723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HiTyperNoML</th>\n",
       "      <td>5.995558</td>\n",
       "      <td>3.207847</td>\n",
       "      <td>4.389024</td>\n",
       "      <td>-2.940777</td>\n",
       "      <td>-2.679158</td>\n",
       "      <td>-2.685296</td>\n",
       "      <td>-2.602917</td>\n",
       "      <td>-2.684282</td>\n",
       "      <td>-0.172112</td>\n",
       "      <td>0.395558</td>\n",
       "      <td>-2.547257</td>\n",
       "      <td>0.448329</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             callable_return  callable_parameter  single_target_assign  \\\n",
       "Typilus             3.874467            2.706296              3.489011   \n",
       "Type4Py             2.217684            2.859436              3.373194   \n",
       "TypeT5              4.795902            3.181719              1.071651   \n",
       "HiTyperNoML         5.995558            3.207847              4.389024   \n",
       "\n",
       "             aug_assign  multi_target_assign  instance_attribute  for_target  \\\n",
       "Typilus       -3.001380            -4.281214            6.150919   -5.347908   \n",
       "Type4Py       -3.571859            -3.908485            6.777593   -4.416800   \n",
       "TypeT5        -2.386550            -3.962651            4.143336   -2.875358   \n",
       "HiTyperNoML   -2.940777            -2.679158           -2.685296   -2.602917   \n",
       "\n",
       "             with_target      loop  reassigned    nested  flow_control  \n",
       "Typilus        -3.590191  1.062420   -4.436911 -0.463867     -1.084221  \n",
       "Type4Py        -3.330763  0.328432   -1.378490  0.237225     -0.804004  \n",
       "TypeT5         -3.968049 -1.348880   -1.567721 -2.528010     -0.845723  \n",
       "HiTyperNoML    -2.684282 -0.172112    0.395558 -2.547257      0.448329  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(coeff_table := pd.concat(\n",
    "    [typilus_coeffs, type4py_coeffs, typet5_coeffs, hityper_coeffs],\n",
    "    keys=[\"Typilus\", \"Type4Py\", \"TypeT5\", \"HiTyperNoML\"],\n",
    "    axis=0,\n",
    ").reset_index(level=1, drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "5d75b374-435b-46f5-82ed-ede7ac8671a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrrrrrrrr}\n",
      "\\toprule\n",
      " & Ret & Param & Assgn & AugAssgn & MultAssgn & InstAttr & ForInit & WithInit & Loop & Reassigned & Nested & Flow \\\\\n",
      "\\midrule\n",
      "Typilus & 3.87 & 2.71 & 3.49 & -3.00 & -4.28 & 6.15 & -5.35 & -3.59 & 1.06 & -4.44 & -0.46 & -1.08 \\\\\n",
      "Type4Py & 2.22 & 2.86 & 3.37 & -3.57 & -3.91 & 6.78 & -4.42 & -3.33 & 0.33 & -1.38 & 0.24 & -0.80 \\\\\n",
      "TypeT5 & 4.80 & 3.18 & 1.07 & -2.39 & -3.96 & 4.14 & -2.88 & -3.97 & -1.35 & -1.57 & -2.53 & -0.85 \\\\\n",
      "HiTyperNoML & 6.00 & 3.21 & 4.39 & -2.94 & -2.68 & -2.69 & -2.60 & -2.68 & -0.17 & 0.40 & -2.55 & 0.45 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(coeff_table.rename(columns={\n",
    "    \"callable_return\": \"Ret\",\n",
    "    \"callable_parameter\": \"Param\",\n",
    "    \"single_target_assign\": \"Assgn\",\n",
    "    \"aug_assign\": \"AugAssgn\",\n",
    "    \"multi_target_assign\": \"MultAssgn\",\n",
    "    \"instance_attribute\": \"InstAttr\",\n",
    "    \"for_target\": \"ForInit\",\n",
    "    \"with_target\": \"WithInit\",\n",
    "    \"loop\": \"Loop\",\n",
    "    \"reassigned\": \"Reassigned\",\n",
    "    \"nested\": \"Nested\",\n",
    "    \"flow_control\": \"Flow\"\n",
    "}).to_latex(float_format=\"{:.2f}\".format))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
