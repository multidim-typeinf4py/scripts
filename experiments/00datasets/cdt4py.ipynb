{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-09T11:55:24.391361234Z",
     "start_time": "2023-08-09T11:55:24.349034020Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%pwd\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.expand_frame_repr\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "c2c4e7858c5f1ad5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-09T11:55:25.853267954Z",
     "start_time": "2023-08-09T11:55:25.839897361Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-07 12:05:36,084 | INFO : Hello World\n"
     ]
    }
   ],
   "source": [
    "import pathlib, sys\n",
    "import logging\n",
    "\n",
    "DATA_FOLDER = pathlib.Path(\"/nfs/data/students/bsparks/mdti4py-dataset-pool/cdt4py/\")\n",
    "assert DATA_FOLDER.is_dir()\n",
    "\n",
    "logger = logging.getLogger(name=__name__)\n",
    "logger.handlers.clear()\n",
    "logger.setLevel(level=logging.DEBUG)\n",
    "\n",
    "handler = logging.StreamHandler(stream=sys.stdout)\n",
    "handler.setFormatter(fmt=logging.Formatter('%(asctime)s | %(levelname)s : %(message)s'))\n",
    "logger.addHandler(handler)\n",
    "\n",
    "logger.info(\"Hello World\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "6c08c2beed07bc6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-07 12:05:39,456 | DEBUG : CrossDomainTypes4Py @ /nfs/data/students/bsparks/mdti4py-dataset-pool/cdt4py\n"
     ]
    }
   ],
   "source": [
    "from typet5.data import GitRepo\n",
    "from scripts.infer.structure import CrossDomainTypes4Py\n",
    "\n",
    "dataset = CrossDomainTypes4Py(dataset_root=DATA_FOLDER)\n",
    "logger.debug(dataset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "645a1dcfef8d7de2",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-08-09T11:55:27.320208232Z"
    }
   },
   "outputs": [],
   "source": [
    "from scripts.infer.structure import AuthorRepo\n",
    "from typet5.data import GitRepo\n",
    "\n",
    "\n",
    "class CDT4PyRepo(GitRepo):\n",
    "    def __init__(self, author_repo: AuthorRepo) -> None:\n",
    "        super().__init__(\n",
    "            author=author_repo.author,\n",
    "            name=author_repo.repo,\n",
    "            url=None,\n",
    "            stars=-1,\n",
    "            forks=-1\n",
    "        )\n",
    "        \n",
    "    def authorname(self) -> str:\n",
    "        return f\"{self.author}/{self.name}\"\n",
    "        \n",
    "\n",
    "class CDT4PyFlaskRepo(CDT4PyRepo):\n",
    "    def repo_dir(self, repos_dir: pathlib.Path) -> pathlib.Path:\n",
    "        return repos_dir / \"flask\" / self.authorname()\n",
    "    \n",
    "class CDT4PyNumpyRepo(CDT4PyRepo):\n",
    "    def repo_dir(self, repos_dir: pathlib.Path) -> pathlib.Path:\n",
    "        return repos_dir / \"numpy\"  / self.authorname()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "ebbb9c54-e301-4dd9-9f47-2f3d68960297",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6706"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cdt4py_author_repos: dict[AuthorRepo, pathlib.Path] = {\n",
    "    dataset.author_repo(repository): repository\n",
    "    for repository in dataset.project_iter()\n",
    "}\n",
    "display(len(cdt4py_author_repos))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ab3252-d821-4313-9210-745303790651",
   "metadata": {},
   "source": [
    "# Remove BetterTypes4Py, Typilus and Type4Py datasets from CrossDomainTypes4Py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "db620f74-53d0-44e2-9cde-585a0584efba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "dataset_path = pathlib.Path(\"/nfs/data/students/bsparks/mdti4py-dataset-pool/cdt4py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0d66ecda-ae96-4008-80b3-47d7efaa8e24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b607cef28c04871b1ce9751689554fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/211442 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied 149528 files\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import shutil, os\n",
    "\n",
    "src_mt4py_dataset = pathlib.Path(\"/nfs/data/students/bsparks/many-types-4-py-dataset\")\n",
    "dest_mt4py_dataset = pathlib.Path(\"/nfs/data/students/bsparks/mdti4py-datasets/many-types-4-py-dataset\")\n",
    "\n",
    "mt4py_split_df = pd.read_csv(src_mt4py_dataset / \"data/dataset_split.csv\", names=[\"split\", \"file\"])\n",
    "copied = 0\n",
    "for file in tqdm(mt4py_split_df[mt4py_split_df.split == \"train\"].file):\n",
    "    if not os.path.exists(src_fpath := os.path.join(str(src_mt4py_dataset), file)):\n",
    "        continue\n",
    "    \n",
    "    dest_fpath = os.path.join(str(dest_mt4py_dataset), file)\n",
    "    \n",
    "    os.makedirs(os.path.dirname(dest_fpath), exist_ok=True)\n",
    "    shutil.copy(src_fpath, dest_fpath)\n",
    "\n",
    "    copied += 1\n",
    "\n",
    "print(f\"Copied {copied} files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4650ee63-fce1-4fe2-8ba4-5560712e84f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /nfs/data/students/bsparks/mdti4py-datasets/many-types-4-py-dataset/repos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "181fe87c-c9ae-4ffc-acca-4f2e7b1771d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "many-types-4-py-dataset  tt5-train  typilus\n"
     ]
    }
   ],
   "source": [
    "!ls /nfs/data/students/bsparks/mdti4py-datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7961ec15-bb08-436d-9000-7bc90763b1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install cd4py\n",
    "!pip install \"typing_extensions==4.5.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6294c6-c5cb-4ff6-ae0e-1c1a06a1f4a1",
   "metadata": {},
   "source": [
    "Number of source code files: 2,604,611                                                                                \n",
    "[I 2023-09-07 14:03:50.700 ServerApp] Saving file at /experiments/00datasets/cdt4py.ipynb                            │Total number of tokens: 1,268,703,455                                                                                 \n",
    "[I 2023-09-07 14:05:50.926 ServerApp] Saving file at /experiments/00datasets/cdt4py.ipynb                            │100%|█████████████████████████████████████████████████████████████████████| 2604611/2604611 [05:56<00:00, 7315.22it/s]\n",
    "[W 2023-09-07 17:52:42.791 ServerApp] WebSocket ping timeout after 119980 ms.                                        │100%|█████████████████████████████████████████████████████████████████████| 2604611/2604611 [12:04<00:00, 3596.45it/s]\n",
    "[I 2023-09-07 17:52:47.792 ServerApp] Starting buffering for 86de0c3c-afd7-4dac-bf0d-24991e3d37cb:2196c57f-60da-4220-│***********************Vectorize pre-processed source code files using TF-IDF**********************                   \n",
    "8563-671aa53816b7                                                                                                    │100%|█████████████████████████████████████████████████████████████████████| 2604611/2604611 [21:26<00:00, 2023.87it/s]\n",
    "[I 2023-09-08 17:42:51.424 ServerApp] 302 GET / (@127.0.0.1) 0.92ms                                                  │**************************Building KNN index and finding nearest neighbors*************************                   \n",
    "[W 2023-09-08 17:42:53.855 LabApp] Could not determine jupyterlab build status without nodejs                        │100%|█████████████████████████████████████████████████████████████████████| 2604611/2604611 [05:55<00:00, 7336.19it/s]\n",
    "[I 2023-09-08 17:42:54.006 ServerApp] Connecting to kernel cf8cb073-e5b3-4c1c-b385-c6ccc37efb55.                     │100%|██████████████████████████████████████████████████████████████████████| 2604611/2604611 [50:09<00:00, 865.38it/s]\n",
    "[I 2023-09-08 17:42:54.058 ServerApp] Connecting to kernel 9fc37da9-cbb6-4566-928d-99f2fee6a601.                     │*******************************Finding exact and near duplicate files******************************                   \n",
    "[I 2023-09-08 17:42:54.097 ServerApp] Connecting to kernel 86de0c3c-afd7-4dac-bf0d-24991e3d37cb.                     │100%|█████████████████████████████████████████████████████████████████████| 2604611/2604611 [07:46<00:00, 5580.31it/s]\n",
    "[I 2023-09-08 17:42:54.332 ServerApp] Starting buffering for cf8cb073-e5b3-4c1c-b385-c6ccc37efb55:fc69da8c-75c8-4c77-│*********************Report duplication stats & saving detected duplicate files********************                   \n",
    "9f70-ba2e4aa42f86                                                                                                    │Number of duplicated files: 2,417,250 (92.81%)                                                                        \n",
    "[I 2023-09-08 17:42:54.333 ServerApp] Starting buffering for 9fc37da9-cbb6-4566-928d-99f2fee6a601:c7f7880b-5671-4bba-│Number of detected clusters: 184,937                                                                                  \n",
    "be2d-b039572025d3                                                                                                    │Avg. number of files per clones: 13.07                                                                                \n",
    "[I 2023-09-08 17:42:54.334 ServerApp] Starting buffering for 86de0c3c-afd7-4dac-bf0d-24991e3d37cb:3b942345-73e7-49ea-│Median number of files per clones: 4.00                                                                               \n",
    "81d8-45e8e8e83e92                                                                                                    │Duplication ratio: 85.71%                                                                                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b983a1ed-9ba8-41fd-b6f2-85805454ecd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: cd4py [-h] --p P --od OD --ot OT [--d D] [--th TH] [--k K] [--tr TR]\n",
      "\n",
      "Code De-Duplication for Python\n",
      "\n",
      "options:\n",
      "  -h, --help  show this help message and exit\n",
      "  --p P       Path to Python projects\n",
      "  --od OD     Output folder to store detected duplicate files.\n",
      "  --ot OT     Output folder to store tokenized files.\n",
      "  --d D       Dimension of TF-IDF vectors [default: 2048].\n",
      "  --th TH     Threshold to identify duplicate files [default: 0.95].\n",
      "  --k K       Number of nearest neighbor [default: 10].\n",
      "  --tr TR     Number trees to build the index. More trees gives higher\n",
      "              precision but slower [default: 20].\n"
     ]
    }
   ],
   "source": [
    "!cd4py --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7b41e0-abba-43d8-960f-4926cf6971c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************************Tokenizing Python source code files*********************************\n",
      "100%|████████████████████████████████████████████| 4/4 [00:00<00:00, 423.72it/s]\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/many-types-4-py-dataset/repos/visit-dav/visit-deps/windowsbuild/MSVC2017/python/3.7.7/Lib/test/bad_coding2.py because encoding problem for '/nfs/data/students/bsparks/mdti4py-dataset-pool/many-types-4-py-dataset/repos/visit-dav/visit-deps/windowsbuild/MSVC2017/python/3.7.7/Lib/test/bad_coding2.py': utf-8\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/many-types-4-py-dataset/repos/visit-dav/visit-deps/windowsbuild/MSVC2017/python/3.7.7/Lib/test/bad_coding.py because unknown encoding for '/nfs/data/students/bsparks/mdti4py-dataset-pool/many-types-4-py-dataset/repos/visit-dav/visit-deps/windowsbuild/MSVC2017/python/3.7.7/Lib/test/bad_coding.py': uft-8\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/many-types-4-py-dataset/repos/skeept/dotvim/pack/bundle/opt/neomake/tests/fixtures/errors.py because ('EOF in multi-line statement', (2, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/highweb-project.highweb-webcl-html5spec/tools/android/mempressure.py because ('EOF in multi-line statement', (115, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/many-types-4-py-dataset/repos/NoskovIvan/Coinlist-NuCypher-Hackathon/examples/finnegans_wake_demo/numedia.py because unindent does not match any outer indentation level (<tokenize>, line 82)\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/PyCQA.pycodestyle/testsuite/E90.py because unindent does not match any outer indentation level (<tokenize>, line 9)\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/many-types-4-py-dataset/repos/sagarvs707/Viyaan/venv/Lib/site-packages/pylint/test/functional/tokenize_error.py because ('EOF in multi-line statement', (7, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/many-types-4-py-dataset/repos/sagarvs707/Viyaan/venv/Lib/site-packages/pylint/test/functional/tokenize_error_jython.py because ('EOF in multi-line statement', (8, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/many-types-4-py-dataset/repos/wtsi-hgi/webhook-router/config-server/configserver/RouteWhitelist.py because unindent does not match any outer indentation level (<tokenize>, line 13)\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/many-types-4-py-dataset/repos/shannon-sys/mongodb/src/third_party/wiredtiger/src/docs/tools/fixlinks.py because ('EOF in multi-line statement', (68, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/many-types-4-py-dataset/repos/Aungmyintmyat97/python-class/PassState.py because unindent does not match any outer indentation level (<tokenize>, line 12)\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/many-types-4-py-dataset/repos/Aungmyintmyat97/python-class/forstate.py because unindent does not match any outer indentation level (<tokenize>, line 59)\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/many-types-4-py-dataset/repos/SynthAI/SynthAI/iaf/graphy/nodes/__init__.py because unindent does not match any outer indentation level (<tokenize>, line 220)\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/e-mission.e-mission-server/emission/pipeline/model_stage.py because ('EOF in multi-line statement', (125, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/many-types-4-py-dataset/repos/sklonely/python/爬蟲/站存區.py because unindent does not match any outer indentation level (<tokenize>, line 3)\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/many-types-4-py-dataset/repos/sklonely/python/DQN/main.py because 'utf-8' codec can't decode byte 0xbe in position 1: invalid start byte\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/many-types-4-py-dataset/repos/DivisionBy-Zero/erpa-sweng/server/secrets/__init__.py because invalid or missing encoding declaration for '/nfs/data/students/bsparks/mdti4py-dataset-pool/many-types-4-py-dataset/repos/DivisionBy-Zero/erpa-sweng/server/secrets/__init__.py'\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/qtile.qtile/test/configs/syntaxerr.py because ('EOF in multi-line statement', (28, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/many-types-4-py-dataset/repos/yongjhih/mender-sdk/tests/test_mender.py because unknown encoding for '/nfs/data/students/bsparks/mdti4py-dataset-pool/many-types-4-py-dataset/repos/yongjhih/mender-sdk/tests/test_mender.py': future_fstrings\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/many-types-4-py-dataset/repos/yongjhih/mender-sdk/mender/__init__.py because unknown encoding for '/nfs/data/students/bsparks/mdti4py-dataset-pool/many-types-4-py-dataset/repos/yongjhih/mender-sdk/mender/__init__.py': future_fstrings\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/many-types-4-py-dataset/repos/psycho14/wpt/tools/wptserve/tests/functional/docroot/invalid.py because ('EOF in multi-line statement', (4, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/many-types-4-py-dataset/repos/EiSandarWin/PythonSample/range.py because unindent does not match any outer indentation level (<tokenize>, line 43)\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/many-types-4-py-dataset/repos/EiSandarWin/PythonSample/Python File IO/write.py because ('EOF in multi-line statement', (24, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/tych0.qtile/test/configs/syntaxerr.py because ('EOF in multi-line statement', (4, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/pyparallel.pyparallel/Lib/test/bad_coding2.py because encoding problem for '/nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/pyparallel.pyparallel/Lib/test/bad_coding2.py': utf-8\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/pyparallel.pyparallel/Lib/test/bad_coding.py because unknown encoding for '/nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/pyparallel.pyparallel/Lib/test/bad_coding.py': uft-8\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/pyparallel.pyparallel/Lib/test/badsyntax_pep3120.py because invalid or missing encoding declaration for '/nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/pyparallel.pyparallel/Lib/test/badsyntax_pep3120.py'\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/many-types-4-py-dataset/repos/zenathark/twitlab/twitlab/core.py because invalid or missing encoding declaration for '/nfs/data/students/bsparks/mdti4py-dataset-pool/many-types-4-py-dataset/repos/zenathark/twitlab/twitlab/core.py'\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/many-types-4-py-dataset/repos/zenathark/twitlab/twitlab/__init__.py because invalid or missing encoding declaration for '/nfs/data/students/bsparks/mdti4py-dataset-pool/many-types-4-py-dataset/repos/zenathark/twitlab/twitlab/__init__.py'\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/many-types-4-py-dataset/repos/thomasm1/python_2018/PY_FUNCTION/range.py because unindent does not match any outer indentation level (<tokenize>, line 13)\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/many-types-4-py-dataset/repos/thomasm1/python_2018/PY_FUNCTION/comprehensiono.py because ('EOF in multi-line statement', (65, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/many-types-4-py-dataset/repos/thomasm1/python_2018/PY_FUNCTION/_CountryCapital.py because 'utf-8' codec can't decode byte 0x91 in position 41: invalid start byte\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/many-types-4-py-dataset/repos/thomasm1/python_2018/PY_FUNCTION/dep_injection.py because unindent does not match any outer indentation level (<tokenize>, line 13)\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/many-types-4-py-dataset/repos/thomasm1/python_2018/PY_FUNCTION/singleton.py because unindent does not match any outer indentation level (<tokenize>, line 17)\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/many-types-4-py-dataset/repos/thomasm1/python_2018/PY_IOT/SenseHat/inertia_measure.py because ('EOF in multi-line statement', (45, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/many-types-4-py-dataset/repos/thomasm1/python_2018/PY_DATA/sandboxScraper.py because ('EOF in multi-line statement', (58, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/many-types-4-py-dataset/repos/thomasm1/python_2018/PY_THREAD/Thread.py because ('EOF in multi-line statement', (40, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/many-types-4-py-dataset/repos/thomasm1/python_2018/PY_GRAPH/pair_plots.py because ('EOF in multi-line statement', (18, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/many-types-4-py-dataset/repos/web-platform-tests/wpt/tools/wptserve/tests/functional/docroot/invalid.py because ('EOF in multi-line statement', (4, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/many-types-4-py-dataset/repos/ykchen12/UserCenter/venv/Scripts/pip-script.py because invalid or missing encoding declaration for '/nfs/data/students/bsparks/mdti4py-dataset-pool/many-types-4-py-dataset/repos/ykchen12/UserCenter/venv/Scripts/pip-script.py'\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/many-types-4-py-dataset/repos/ykchen12/UserCenter/venv/Scripts/easy_install-3.6-script.py because invalid or missing encoding declaration for '/nfs/data/students/bsparks/mdti4py-dataset-pool/many-types-4-py-dataset/repos/ykchen12/UserCenter/venv/Scripts/easy_install-3.6-script.py'\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/ganga-devs.ganga/ganga/GangaND280/examples/RecoAna+Highland.py because ('EOF in multi-line statement', (68, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/many-types-4-py-dataset/repos/yannhyu/breadnbutter/SOAP_WS/PyXML-master/test/dom/borrowed/af_20000922.py because 'utf-8' codec can't decode byte 0xe0 in position 9: invalid continuation byte\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/many-types-4-py-dataset/repos/ben-graves-method/method-pfc-bb/device/utilities/communication/arduino/device_io.py because ('EOF in multi-line statement', (123, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/many-types-4-py-dataset/repos/awslabs/datawig/experiments/benchmarks.py because ('EOF in multi-line statement', (283, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/McStasMcXtrace.McCode/meta-pkgs/windows/Support/gnuplot-py-1.8/gnuplot_Suites.py because 'utf-8' codec can't decode byte 0xd5 in position 78: invalid continuation byte\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/McStasMcXtrace.McCode/meta-pkgs/windows/Support/gnuplot-py-1.8/build/lib.linux-x86_64-2.7/Gnuplot/gnuplot_Suites.py because 'utf-8' codec can't decode byte 0xd5 in position 78: invalid continuation byte\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/many-types-4-py-dataset/repos/catmaid/CATMAID/scripts/old/switch-to-migrations.py because ('EOF in multi-line statement', (122, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/ActiveState.code/recipes/Python/576660_texthtml/recipe-576660.py because 'gb2312' codec can't decode byte 0xe5 in position 1: illegal multibyte sequence\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/ActiveState.code/recipes/Python/440634_Rebind_class_properties/recipe-440634.py because unindent does not match any outer indentation level (<tokenize>, line 70)\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/ActiveState.code/recipes/Python/496702_Templite/recipe-496702.py because unindent does not match any outer indentation level (<tokenize>, line 133)\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/ActiveState.code/recipes/Python/67683_Displaying_Decoded_Hotkeys_Shortcuts/recipe-67683.py because ('EOF in multi-line statement', (28, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/ActiveState.code/recipes/Python/102114_ThreadedContext/recipe-102114.py because ('EOF in multi-line string', (19, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/ActiveState.code/recipes/Python/363219_Use_Jython_to_time_Java_code/recipe-363219.py because ('EOF in multi-line statement', (82, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/ActiveState.code/recipes/Python/580810_How_create_simple_PDF_Pie_Chart_using_fitz_/recipe-580810.py because ('EOF in multi-line statement', (70, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/ActiveState.code/recipes/Python/67084_Assuring_that_entry_valid/recipe-67084.py because ('EOF in multi-line statement', (9, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/ActiveState.code/recipes/Python/577209_pycurl7190_python3_patch_1_of_2/recipe-577209.py because unindent does not match any outer indentation level (<tokenize>, line 5)\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/ActiveState.code/recipes/Python/82826_HOW_DEBUG_PYTHEXTENSIONS_WINDOWS_OPEN_SOURCE/recipe-82826.py because unindent does not match any outer indentation level (<tokenize>, line 29)\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/ActiveState.code/recipes/Python/117239_Simple_JSP_Custom_Tag_in_Jython/recipe-117239.py because unindent does not match any outer indentation level (<tokenize>, line 13)\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/ActiveState.code/recipes/Python/413557_Another_approach_automatic_super/recipe-413557.py because ('EOF in multi-line statement', (111, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/ActiveState.code/recipes/Python/80308_xgetopt_solutimanaging_commnad_line_args_usage/recipe-80308.py because unindent does not match any outer indentation level (<tokenize>, line 200)\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/ActiveState.code/recipes/Python/576672_Another_use/recipe-576672.py because unindent does not match any outer indentation level (<tokenize>, line 44)\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/ActiveState.code/recipes/Python/576407_Quadratic/recipe-576407.py because unindent does not match any outer indentation level (<tokenize>, line 31)\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/ActiveState.code/recipes/Python/189745_Symmetric_datobfuscatiusing/recipe-189745.py because unindent does not match any outer indentation level (<tokenize>, line 4)\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/ActiveState.code/recipes/Python/576724_Rot13_Quine/recipe-576724.py because 'rot13' is not a text encoding; use codecs.decode() to handle arbitrary codecs\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/ActiveState.code/recipes/Python/573461_Publish_list_data_as_CSV_file/recipe-573461.py because ('EOF in multi-line statement', (25, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/ActiveState.code/recipes/Python/578174_KYSU_Keep_Your_Stuff_Updated/recipe-578174.py because unindent does not match any outer indentation level (<tokenize>, line 74)\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/ActiveState.code/recipes/Python/305318_using_operator__module__wmap_plus_bit_/recipe-305318.py because ('EOF in multi-line statement', (101, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/ActiveState.code/recipes/Python/576513_Ellipse/recipe-576513.py because ('EOF in multi-line statement', (58, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/ActiveState.code/recipes/Python/578773_Delete_a_GtkTreeView_row/recipe-578773.py because unindent does not match any outer indentation level (<tokenize>, line 62)\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/ActiveState.code/recipes/Python/578080_Libreenect_OpenKinect_Minimum_Value_Joystick/recipe-578080.py because ('EOF in multi-line statement', (133, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/ActiveState.code/recipes/Python/541102_Enhanced_Complex_Number_Type/recipe-541102.py because unindent does not match any outer indentation level (<tokenize>, line 69)\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/ActiveState.code/recipes/Python/391249_Error_reporting_via_decorator/recipe-391249.py because ('EOF in multi-line statement', (77, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/ActiveState.code/recipes/Python/578985_How_read_input_txt_file_pythoutput/recipe-578985.py because unindent does not match any outer indentation level (<tokenize>, line 2)\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/ActiveState.code/recipes/Python/579069_stupid_trick_mimicking_pythcgi_librarys/recipe-579069.py because unindent does not match any outer indentation level (<tokenize>, line 25)\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/ActiveState.code/recipes/Python/102109_Colorize_xml_source_using_sax_ContentHandler/recipe-102109.py because unindent does not match any outer indentation level (<tokenize>, line 235)\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/ActiveState.code/recipes/Python/415500_Quickslice_decorator_Abbreviated_slice/recipe-415500.py because ('EOF in multi-line statement', (131, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/many-types-4-py-dataset/repos/p02e909/web_mk/exercises/ex7_3.py because ('EOF in multi-line statement', (70, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/ActiveState.code/recipes/Python/528872_Contract_verification_in_Python/recipe-528872.py because unindent does not match any outer indentation level (<tokenize>, line 9)\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/ActiveState.code/recipes/Python/302592_Threaded_FTP_Client/recipe-302592.py because ('EOF in multi-line statement', (536, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/ActiveState.code/recipes/Python/496869_Computing_permutations/recipe-496869.py because unindent does not match any outer indentation level (<tokenize>, line 69)\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/ActiveState.code/recipes/Python/159462_How_to_Set_Environment_Variables/recipe-159462.py because ('EOF in multi-line statement', (27, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/ActiveState.code/recipes/Python/496905_ActiveRecord_like_ORM_object_relatimapper_200/recipe-496905.py because ('EOF in multi-line statement', (277, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/ActiveState.code/recipes/Python/152043_Simple_telnet_session_scripting/recipe-152043.py because ('EOF in multi-line statement', (108, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/ActiveState.code/recipes/Python/415353_Threaded_Queue_Minder/recipe-415353.py because unindent does not match any outer indentation level (<tokenize>, line 40)\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/ActiveState.code/recipes/Python/574436_py3to2__testdevelopintegrate_pyth30_code/recipe-574436.py because unindent does not match any outer indentation level (<tokenize>, line 552)\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/ActiveState.code/recipes/Python/579089_PythGpCgpCalculator_Annuniversity__forked/recipe-579089.py because ('EOF in multi-line string', (117, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/ActiveState.code/recipes/Python/574437_py3to2__testdevelopintegrate_pyth30_code/recipe-574437.py because unindent does not match any outer indentation level (<tokenize>, line 552)\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/ActiveState.code/recipes/Python/577439_Simple_commsubmitter/recipe-577439.py because unindent does not match any outer indentation level (<tokenize>, line 75)\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/ActiveState.code/recipes/Python/224043_Customizing_urllib_library_fetch_web_pages_way/recipe-224043.py because unindent does not match any outer indentation level (<tokenize>, line 50)\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/many-types-4-py-dataset/repos/mozilla/gecko-dev/tools/lint/test/files/black/invalid.py because ('EOF in multi-line statement', (5, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/ActiveState.code/recipes/Python/172431_Ensuring_name_definitimodule/recipe-172431.py because ('EOF in multi-line statement', (35, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/ActiveState.code/recipes/Python/576574_Login_Logger/recipe-576574.py because unindent does not match any outer indentation level (<tokenize>, line 71)\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/ActiveState.code/recipes/Python/130004_Releasing_Resource_used/recipe-130004.py because ('EOF in multi-line statement', (61, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/ActiveState.code/recipes/Python/305292_doctest_unittest_pyth24s_cool_/recipe-305292.py because unindent does not match any outer indentation level (<tokenize>, line 33)\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/google.pytype/pytype/test_data/tokenerror2.py because ('EOF in multi-line statement', (4, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/google.pytype/pytype/test_data/tokenerror1.py because ('EOF in multi-line string', (2, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/google.pytype/pytype/tools/merge_pyi/test_data/pyi_variations.comment.py because unindent does not match any outer indentation level (<tokenize>, line 34)\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/many-types-4-py-dataset/repos/the-virtual-brain/tvb-hpc/phase_plane_interactive/cuda_template.py because ('EOF in multi-line statement', (71, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/many-types-4-py-dataset/repos/alexboy60318/project_NLP/Music_NEW/11/musics/vt.py because 'utf-8' codec can't decode byte 0xc0 in position 58: invalid start byte\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/many-types-4-py-dataset/repos/yishenggudou/blog/pelican-blog/plugins/asciidoc_reader/asciidoc_reader.py because 'utf-8' codec can't decode byte 0xf1 in position 66: invalid continuation byte\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/many-types-4-py-dataset/repos/pd-biskup/aggregator/aggregator/aggregator/register.py because unindent does not match any outer indentation level (<tokenize>, line 29)\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/many-types-4-py-dataset/repos/dunossauro/live-de-python/codigo/Live115/teste.py because unindent does not match any outer indentation level (<tokenize>, line 10)\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/many-types-4-py-dataset/repos/servo/servo/tests/wpt/web-platform-tests/tools/wptserve/tests/functional/docroot/invalid.py because ('EOF in multi-line statement', (4, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/many-types-4-py-dataset/repos/huoweikong/Myprojects_python_pycharm/实验室小程序/BCA定量 PBS.py because unindent does not match any outer indentation level (<tokenize>, line 23)\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/many-types-4-py-dataset/repos/pawlaczyk/UAM_graf/graph_2.py because 'utf-8' codec can't decode byte 0xf3 in position 4: invalid continuation byte\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/yhyu13.AlphaGOZero-python-tensorflow/support/go-NN-master/engine/OnlineExampleMaker.py because ('EOF in multi-line statement', (134, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/yhyu13.AlphaGOZero-python-tensorflow/model/APV_MCTS_tree.py because unknown encoding for '/nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/yhyu13.AlphaGOZero-python-tensorflow/model/APV_MCTS_tree.py': future_fstrings\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/genova.rapidsms-senegal/apps/khoss/app.py because unindent does not match any outer indentation level (<tokenize>, line 93)\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/genova.rapidsms-senegal/apps/seddo/app.py because 'utf-8' codec can't decode byte 0xe9 in position 43: invalid continuation byte\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/flavour.ifrc/modules/unit_tests/s3/s3validators.py because 'utf-8' codec can't decode byte 0xb0 in position 33: invalid start byte\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/oilshell.oil/Python-2.7.13/Lib/test/bad_coding3.py because unknown encoding for '/nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/oilshell.oil/Python-2.7.13/Lib/test/bad_coding3.py': string-escape\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/oilshell.oil/Python-2.7.13/Lib/test/bad_coding2.py because encoding problem for '/nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/oilshell.oil/Python-2.7.13/Lib/test/bad_coding2.py': utf-8\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/oilshell.oil/Python-2.7.13/Lib/test/bad_coding.py because unknown encoding for '/nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/oilshell.oil/Python-2.7.13/Lib/test/bad_coding.py': uft-8\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/cdt4py/numpy/ClaytonBrezinski/Docker-WindowsHomeAssistant/Unsupervised Machine Learning.py because ('EOF in multi-line statement', (130, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/naftaliharris.tauthon/Mac/Demo/resources/copyres.py because 'utf-8' codec can't decode byte 0xb9 in position 18: invalid start byte\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/naftaliharris.tauthon/Mac/Demo/applescript/Disk_Copy/Special_Events.py because 'utf-8' codec can't decode byte 0x8e in position 68: invalid start byte\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/naftaliharris.tauthon/Mac/Demo/applescript/Disk_Copy/Standard_Suite.py because 'utf-8' codec can't decode byte 0x8e in position 68: invalid start byte\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/naftaliharris.tauthon/Lib/test/bad_coding3.py because unknown encoding for '/nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/naftaliharris.tauthon/Lib/test/bad_coding3.py': string-escape\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/naftaliharris.tauthon/Lib/test/bad_coding2.py because encoding problem for '/nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/naftaliharris.tauthon/Lib/test/bad_coding2.py': utf-8\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/naftaliharris.tauthon/Lib/test/bad_coding.py because unknown encoding for '/nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/naftaliharris.tauthon/Lib/test/bad_coding.py': uft-8\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/kbengine.kbengine/kbe/src/lib/python/Lib/test/bad_coding2.py because encoding problem for '/nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/kbengine.kbengine/kbe/src/lib/python/Lib/test/bad_coding2.py': utf-8\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/kbengine.kbengine/kbe/src/lib/python/Lib/test/bad_coding.py because unknown encoding for '/nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/kbengine.kbengine/kbe/src/lib/python/Lib/test/bad_coding.py': uft-8\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/kbengine.kbengine/kbe/src/lib/python/Lib/test/badsyntax_pep3120.py because invalid or missing encoding declaration for '/nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/kbengine.kbengine/kbe/src/lib/python/Lib/test/badsyntax_pep3120.py'\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/cdt4py/numpy/ZwangaMukwevho/Design/docs/Design/pycode/user.py because unindent does not match any outer indentation level (<tokenize>, line 4)\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/cdt4py/numpy/cadilhe/freqtrade_2020_tcc/freqtrade/strategy/default_strategy.py because unindent does not match any outer indentation level (<tokenize>, line 23)\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/jython.jython3/lib-python/3.5.1/test/bad_coding2.py because encoding problem for '/nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/jython.jython3/lib-python/3.5.1/test/bad_coding2.py': utf-8\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/jython.jython3/lib-python/3.5.1/test/bad_coding.py because unknown encoding for '/nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/jython.jython3/lib-python/3.5.1/test/bad_coding.py': uft-8\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/jython.jython3/lib-python/3.5.1/test/badsyntax_pep3120.py because invalid or missing encoding declaration for '/nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/jython.jython3/lib-python/3.5.1/test/badsyntax_pep3120.py'\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/jython.jython3/Lib/test/badsyntax_eof1.py because ('EOF in multi-line statement', (6, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/jython.jython3/Misc/__run__.py because invalid or missing encoding declaration for '/nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/jython.jython3/Misc/__run__.py'\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/gcblue.gcblue/bin/Lib/test/bad_coding3.py because unknown encoding for '/nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/gcblue.gcblue/bin/Lib/test/bad_coding3.py': string-escape\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/gcblue.gcblue/bin/Lib/test/bad_coding2.py because encoding problem for '/nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/gcblue.gcblue/bin/Lib/test/bad_coding2.py': utf-8\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/gcblue.gcblue/bin/Lib/test/bad_coding.py because unknown encoding for '/nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/gcblue.gcblue/bin/Lib/test/bad_coding.py': uft-8\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/harmy.kbengine/kbe/res/scripts/common/Lib/test/bad_coding2.py because encoding problem for '/nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/harmy.kbengine/kbe/res/scripts/common/Lib/test/bad_coding2.py': utf-8\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/harmy.kbengine/kbe/res/scripts/common/Lib/test/bad_coding.py because unknown encoding for '/nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/harmy.kbengine/kbe/res/scripts/common/Lib/test/bad_coding.py': uft-8\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/harmy.kbengine/kbe/res/scripts/common/Lib/test/badsyntax_pep3120.py because invalid or missing encoding declaration for '/nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/harmy.kbengine/kbe/res/scripts/common/Lib/test/badsyntax_pep3120.py'\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/harmy.kbengine/kbe/src/lib/python/Lib/test/bad_coding2.py because encoding problem for '/nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/harmy.kbengine/kbe/src/lib/python/Lib/test/bad_coding2.py': utf-8\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/harmy.kbengine/kbe/src/lib/python/Lib/test/bad_coding.py because unknown encoding for '/nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/harmy.kbengine/kbe/src/lib/python/Lib/test/bad_coding.py': uft-8\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/harmy.kbengine/kbe/src/lib/python/Lib/test/badsyntax_pep3120.py because invalid or missing encoding declaration for '/nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/harmy.kbengine/kbe/src/lib/python/Lib/test/badsyntax_pep3120.py'\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/unfoldingWord-dev.tools/uwb/export_chunks.py because ('EOF in multi-line statement', (78, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/nvaccess.nvda/source/comInterfaces/_944DE083_8FB8_45CF_BCB7_C477ACB2F897_0_1_0.py because unknown encoding for '/nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/nvaccess.nvda/source/comInterfaces/_944DE083_8FB8_45CF_BCB7_C477ACB2F897_0_1_0.py': mbcs\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/getpelican.pelican-plugins/asciidoc_reader/asciidoc_reader.py because 'utf-8' codec can't decode byte 0xf1 in position 66: invalid continuation byte\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/MagicStack.MagicPython/test/statements/annotation1.py because unindent does not match any outer indentation level (<tokenize>, line 12)\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/MagicStack.MagicPython/test/strings/bug2.py because ('EOF in multi-line statement', (36, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/MagicStack.MagicPython/test/strings/format9.py because ('EOF in multi-line statement', (47, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/MagicStack.MagicPython/test/strings/format6.py because ('EOF in multi-line statement', (37, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/MagicStack.MagicPython/test/strings/bad3.py because unindent does not match any outer indentation level (<tokenize>, line 34)\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/MagicStack.MagicPython/test/comments/typing4.py because unindent does not match any outer indentation level (<tokenize>, line 40)\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/MagicStack.MagicPython/test/comments/typing1.py because unindent does not match any outer indentation level (<tokenize>, line 19)\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/MagicStack.MagicPython/test/comments/typing2.py because unindent does not match any outer indentation level (<tokenize>, line 13)\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/MagicStack.MagicPython/test/expressions/const3.py because unindent does not match any outer indentation level (<tokenize>, line 25)\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/MagicStack.MagicPython/test/regexp/python7.py because ('EOF in multi-line statement', (57, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/MagicStack.MagicPython/test/regexp/python10.py because ('EOF in multi-line statement', (136, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/MagicStack.MagicPython/test/regexp/python8.py because unindent does not match any outer indentation level (<tokenize>, line 195)\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/MagicStack.MagicPython/test/regexp/python2.py because unindent does not match any outer indentation level (<tokenize>, line 26)\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/MagicStack.MagicPython/test/functions/lambda5.py because unindent does not match any outer indentation level (<tokenize>, line 29)\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/MagicStack.MagicPython/test/functions/decl1.py because unindent does not match any outer indentation level (<tokenize>, line 43)\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/MagicStack.MagicPython/test/functions/decorators8.py because unindent does not match any outer indentation level (<tokenize>, line 13)\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/MagicStack.MagicPython/test/functions/decorators1.py because unindent does not match any outer indentation level (<tokenize>, line 15)\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/MagicStack.MagicPython/test/functions/decl14.py because unindent does not match any outer indentation level (<tokenize>, line 64)\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/MagicStack.MagicPython/test/illegals/illegal1.py because ('EOF in multi-line statement', (49, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/MagicStack.MagicPython/test/illegals/backticks3.py because unindent does not match any outer indentation level (<tokenize>, line 17)\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/MagicStack.MagicPython/test/fstrings/nested3.py because unindent does not match any outer indentation level (<tokenize>, line 34)\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/MagicStack.MagicPython/test/fstrings/simple2.py because ('EOF in multi-line statement', (30, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/MagicStack.MagicPython/test/fstrings/simple8.py because ('EOF in multi-line statement', (25, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/MagicStack.MagicPython/test/fstrings/comment1.py because ('EOF in multi-line statement', (34, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/MagicStack.MagicPython/test/docstrings/mix1.py because unindent does not match any outer indentation level (<tokenize>, line 30)\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/MagicStack.MagicPython/test/docstrings/continuation2.py because unindent does not match any outer indentation level (<tokenize>, line 12)\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/MagicStack.MagicPython/test/docstrings/continuation1.py because unindent does not match any outer indentation level (<tokenize>, line 46)\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/MagicStack.MagicPython/test/docstrings/continuation3.py because unindent does not match any outer indentation level (<tokenize>, line 40)\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/MagicStack.MagicPython/test/docstrings/mix2.py because unindent does not match any outer indentation level (<tokenize>, line 29)\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/MagicStack.MagicPython/test/docstrings/continuation4.py because unindent does not match any outer indentation level (<tokenize>, line 19)\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/SLAPaper.Password-Generator-Python/PasswordConverter/TkUtil.py because [Errno 2] No such file or directory: '/nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/SLAPaper.Password-Generator-Python/PasswordConverter/TkUtil.py'\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/matthiaskramm.corepy/examples/fbdemo.py because ('EOF in multi-line statement', (127, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/cdt4py/numpy/quantapix/qnarre2/proba/test/colorize-fixtures/test-freeze-56377.py because ('EOF in multi-line statement', (5, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/cdt4py/numpy/ThinThinzarHtet/PythonHybridClass/Scope.py because unindent does not match any outer indentation level (<tokenize>, line 179)\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/cdt4py/numpy/JackMcKew/jackmckew.dev/plugins/asciidoc_reader/asciidoc_reader.py because 'utf-8' codec can't decode byte 0xf1 in position 66: invalid continuation byte\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/cdt4py/numpy/yuhonghong7035/conversationai-models/hierarchical_attention_research/han_model/bn_lstm_test.py because ('EOF in multi-line statement', (82, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/python.cpython/Lib/test/bad_coding2.py because encoding problem for '/nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/python.cpython/Lib/test/bad_coding2.py': utf-8\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/python.cpython/Lib/test/bad_coding.py because unknown encoding for '/nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/python.cpython/Lib/test/bad_coding.py': uft-8\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/python.cpython/Lib/test/badsyntax_pep3120.py because invalid or missing encoding declaration for '/nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/python.cpython/Lib/test/badsyntax_pep3120.py'\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/cdt4py/numpy/microsoft/vscode-python/src/test/pythonFiles/signature/basicSig.py because ('EOF in multi-line statement', (3, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/cdt4py/numpy/microsoft/vscode-python/src/test/pythonFiles/typeFormatFiles/elseBlocks4.py because unindent does not match any outer indentation level (<tokenize>, line 144)\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/cdt4py/numpy/microsoft/vscode-python/src/test/pythonFiles/typeFormatFiles/elseBlocksTab.py because unindent does not match any outer indentation level (<tokenize>, line 144)\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/cdt4py/numpy/microsoft/vscode-python/src/test/pythonFiles/typeFormatFiles/elseBlocks2.py because unindent does not match any outer indentation level (<tokenize>, line 144)\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/cdt4py/numpy/microsoft/vscode-python/src/test/pythonFiles/typeFormatFiles/tryBlocks4.py because unindent does not match any outer indentation level (<tokenize>, line 16)\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/cdt4py/numpy/microsoft/vscode-python/src/test/pythonFiles/typeFormatFiles/tryBlocks2.py because unindent does not match any outer indentation level (<tokenize>, line 16)\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/cdt4py/numpy/microsoft/vscode-python/src/test/pythonFiles/typeFormatFiles/tryBlocksTab.py because unindent does not match any outer indentation level (<tokenize>, line 16)\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/cdt4py/numpy/microsoft/vscode-python/src/test/pythonFiles/formatting/fileToFormatOnEnter.py because ('EOF in multi-line string', (13, 2))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/dropbox.pyston/test/cpython/bad_coding2.py because encoding problem for '/nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/dropbox.pyston/test/cpython/bad_coding2.py': utf-8\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/dropbox.pyston/test/cpython/bad_coding.py because unknown encoding for '/nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/dropbox.pyston/test/cpython/bad_coding.py': uft-8\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/dropbox.pyston/from_cpython/Lib/test/bad_coding3.py because unknown encoding for '/nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/dropbox.pyston/from_cpython/Lib/test/bad_coding3.py': string-escape\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/dropbox.pyston/from_cpython/Lib/test/bad_coding2.py because encoding problem for '/nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/dropbox.pyston/from_cpython/Lib/test/bad_coding2.py': utf-8\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/dropbox.pyston/from_cpython/Lib/test/bad_coding.py because unknown encoding for '/nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/dropbox.pyston/from_cpython/Lib/test/bad_coding.py': uft-8\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/cdt4py/numpy/aneels3/Algorithm/HackerRank Problem/Python/Pairs.py because ('EOF in multi-line string', (22, 48))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/brython-dev.brython/www/src/Lib/test/bad_coding2.py because encoding problem for '/nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/brython-dev.brython/www/src/Lib/test/bad_coding2.py': utf-8\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/brython-dev.brython/www/src/Lib/test/bad_coding.py because unknown encoding for '/nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/brython-dev.brython/www/src/Lib/test/bad_coding.py': uft-8\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/brython-dev.brython/www/src/Lib/test/badsyntax_pep3120.py because invalid or missing encoding declaration for '/nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/brython-dev.brython/www/src/Lib/test/badsyntax_pep3120.py'\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/gavinp.chromium/third_party/mesa/MesaLib/src/gallium/drivers/llvmpipe/lp_tile_shuffle_mask.py because ('EOF in multi-line statement', (33, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/PyCQA.pylint/tests/functional/invalid_encoded_data.py because 'utf-8' codec can't decode byte 0xd1 in position 11: invalid continuation byte\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/PyCQA.pylint/tests/functional/unknown_encoding_jython.py because unknown encoding for '/nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/PyCQA.pylint/tests/functional/unknown_encoding_jython.py': IBO-8859-1\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/PyCQA.pylint/tests/functional/tokenize_error.py because ('EOF in multi-line statement', (7, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/PyCQA.pylint/tests/functional/tokenize_error_jython.py because ('EOF in multi-line statement', (8, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/PyCQA.pylint/tests/functional/unknown_encoding_py29.py because unknown encoding for '/nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/PyCQA.pylint/tests/functional/unknown_encoding_py29.py': IBO-8859-1\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/cuauv.software/serial/libserial/tests/proto/DeviceConfig_pb2.py because [Errno 2] No such file or directory: '/nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/cuauv.software/serial/libserial/tests/proto/DeviceConfig_pb2.py'\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/cuauv.software/serial/util/DeviceConfig_pb2.py because [Errno 2] No such file or directory: '/nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/cuauv.software/serial/util/DeviceConfig_pb2.py'\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/cuauv.software/serial/seriald/test/device/util/DeviceConfig_pb2.py because [Errno 2] No such file or directory: '/nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/cuauv.software/serial/seriald/test/device/util/DeviceConfig_pb2.py'\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/kiniou.qtile/test/configs/syntaxerr.py because ('EOF in multi-line statement', (25, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/leighpauls.k2cro4/third_party/python_26/Lib/test/bad_coding2.py because encoding problem for '/nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/leighpauls.k2cro4/third_party/python_26/Lib/test/bad_coding2.py': utf-8\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/leighpauls.k2cro4/third_party/python_26/Lib/test/bad_coding.py because unknown encoding for '/nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/leighpauls.k2cro4/third_party/python_26/Lib/test/bad_coding.py': uft-8\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/leighpauls.k2cro4/third_party/python_26/Lib/site-packages/win32com/test/testGatewayAddresses.py because 'utf-8' codec can't decode byte 0x92 in position 61: invalid start byte\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/leighpauls.k2cro4/third_party/mesa/MesaLib/src/gallium/drivers/llvmpipe/lp_tile_shuffle_mask.py because ('EOF in multi-line statement', (33, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/plxaye.chromium/src/third_party/mesa/MesaLib/src/gallium/drivers/llvmpipe/lp_tile_shuffle_mask.py because ('EOF in multi-line statement', (33, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/FFMG.myoddweb.piger/monitor/api/python/Python-3.7.2/Lib/test/bad_coding2.py because encoding problem for '/nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/FFMG.myoddweb.piger/monitor/api/python/Python-3.7.2/Lib/test/bad_coding2.py': utf-8\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/FFMG.myoddweb.piger/monitor/api/python/Python-3.7.2/Lib/test/bad_coding.py because unknown encoding for '/nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/FFMG.myoddweb.piger/monitor/api/python/Python-3.7.2/Lib/test/bad_coding.py': uft-8\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/FFMG.myoddweb.piger/monitor/api/python/Python-3.7.2/Lib/test/badsyntax_pep3120.py because invalid or missing encoding declaration for '/nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/FFMG.myoddweb.piger/monitor/api/python/Python-3.7.2/Lib/test/badsyntax_pep3120.py'\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/FFMG.myoddweb.piger/myodd/boost/tools/build/test/template.py because ('EOF in multi-line statement', (43, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/webbju.android-plus-plus/contrib/python-x86/lib/python2.7/test/bad_coding2.py because encoding problem for '/nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/webbju.android-plus-plus/contrib/python-x86/lib/python2.7/test/bad_coding2.py': utf-8\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/webbju.android-plus-plus/contrib/python-x86/lib/python2.7/test/bad_coding.py because unknown encoding for '/nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/webbju.android-plus-plus/contrib/python-x86/lib/python2.7/test/bad_coding.py': uft-8\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/cdt4py/numpy/SuLaePhyuSin/SFUpython/If_Else_Statement.py because unindent does not match any outer indentation level (<tokenize>, line 78)\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/cdt4py/numpy/SuLaePhyuSin/SFUpython/One.py because ('EOF in multi-line statement', (90, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/cdt4py/numpy/SuLaePhyuSin/SFUpython/1.py because ('EOF in multi-line statement', (114, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/webbju.android-plus-plus/contrib/python-x86_64/lib/python2.7/test/bad_coding2.py because encoding problem for '/nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/webbju.android-plus-plus/contrib/python-x86_64/lib/python2.7/test/bad_coding2.py': utf-8\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/webbju.android-plus-plus/contrib/python-x86_64/lib/python2.7/test/bad_coding.py because unknown encoding for '/nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/webbju.android-plus-plus/contrib/python-x86_64/lib/python2.7/test/bad_coding.py': uft-8\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/meego-tablet-ux.meego-app-browser/third_party/mesa/MesaLib/src/gallium/drivers/llvmpipe/lp_tile_shuffle_mask.py because ('EOF in multi-line statement', (33, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/meego-tablet-ux.meego-app-browser/chrome/test/webdriver/webdriver_remote_tests.py because unindent does not match any outer indentation level (<tokenize>, line 122)\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/cdt4py/numpy/malyginaleksander/My_regression/Regression/Data Services/ep_net_1/02_marketing/test_promo_01_add.py because ('EOF in multi-line statement', (70, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/cdt4py/numpy/cameronaaron/conversationai-models/hierarchical_attention_research/han_model/bn_lstm_test.py because ('EOF in multi-line statement', (82, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/cdt4py/numpy/jackyho112/airflow-playground/airflow-section-3/mnt/airflow/dags/forex_data_pipeline.py because unindent does not match any outer indentation level (<tokenize>, line 79)\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/henkelis.sonospy/sonospy/querysonos.py because unindent does not match any outer indentation level (<tokenize>, line 225)\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/cdt4py/numpy/KhantThu27/Python-Class/Variable.py because ('EOF in multi-line statement', (56, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/davidhalter.jedi/test/completion/parser.py because ('EOF in multi-line statement', (44, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/davidhalter.jedi/test/completion/comprehensions.py because ('EOF in multi-line statement', (259, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/davidhalter.jedi/test/completion/invalid.py because ('EOF in multi-line statement', (215, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/davidhalter.jedi/test/completion/definition.py because ('EOF in multi-line statement', (69, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/davidhalter.jedi/test/completion/fstring.py because ('EOF in multi-line statement', (39, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/davidhalter.jedi/test/completion/named_param.py because ('EOF in multi-line statement', (63, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/jythontools.jython/lib-python/2.7/test/bad_coding2.py because encoding problem for '/nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/jythontools.jython/lib-python/2.7/test/bad_coding2.py': utf-8\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/jythontools.jython/lib-python/2.7/test/bad_coding.py because unknown encoding for '/nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/jythontools.jython/lib-python/2.7/test/bad_coding.py': uft-8\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/cdt4py/numpy/CHITMINTHU123/SFUpython/One.py because unindent does not match any outer indentation level (<tokenize>, line 64)\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/cdt4py/numpy/CHITMINTHU123/SFUpython/Game/One.py because unindent does not match any outer indentation level (<tokenize>, line 64)\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/jythontools.jython/Lib/test/bad_coding2.py because unknown encoding for '/nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/jythontools.jython/Lib/test/bad_coding2.py': uft8\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/jythontools.jython/Lib/test/latin1_no_encoding.py because invalid or missing encoding declaration for '/nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/jythontools.jython/Lib/test/latin1_no_encoding.py'\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/jythontools.jython/Lib/test/invalid_utf_8_declared_encoding.py because 'utf-8' codec can't decode byte 0xff in position 5: invalid start byte\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/jythontools.jython/Lib/test/badsyntax_eof1.py because ('EOF in multi-line statement', (6, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/jythontools.jython/Misc/__run__.py because invalid or missing encoding declaration for '/nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/jythontools.jython/Misc/__run__.py'\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/xianhu.LearnPython/python_base.py because unindent does not match any outer indentation level (<tokenize>, line 1113)\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/LumaPictures.pymel/pymel/cache/mayaApi2018.py because 'utf-8' codec can't decode byte 0xc2 in position 65: invalid continuation byte\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/LumaPictures.pymel/pymel/cache/mayaApi2017.py because 'utf-8' codec can't decode byte 0xc2 in position 65: invalid continuation byte\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/dvklopfenstein.PrincetonAlgorithms/tests/test_EdgeWeightedDirectedCycle.py because ('EOF in multi-line statement', (61, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/dvklopfenstein.PrincetonAlgorithms/tests/test_FordFulkerson.py because ('EOF in multi-line statement', (48, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/dvklopfenstein.PrincetonAlgorithms/tests/test_GREP.py because ('EOF in multi-line statement', (47, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/dvklopfenstein.PrincetonAlgorithms/tests/test_DijkstraSP.py because ('EOF in multi-line statement', (56, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/dvklopfenstein.PrincetonAlgorithms/tests/test_BellmanFordSP.py because ('EOF in multi-line statement', (64, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/dvklopfenstein.PrincetonAlgorithms/tests/test_NFA.py because ('EOF in multi-line statement', (46, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/dvklopfenstein.PrincetonAlgorithms/py/AlgsSedgewickWayne/KosarajuSharirSCC.py because ('EOF in multi-line statement', (247, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/dvklopfenstein.PrincetonAlgorithms/py/AlgsSedgewickWayne/GrahamScan.py because ('EOF in multi-line statement', (242, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/dvklopfenstein.PrincetonAlgorithms/py/AlgsSedgewickWayne/RedBlackBST.py because ('EOF in multi-line statement', (518, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/dvklopfenstein.PrincetonAlgorithms/py/AlgsSedgewickWayne/FileIndex.py because ('EOF in multi-line statement', (99, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/dvklopfenstein.PrincetonAlgorithms/py/AlgsSedgewickWayne/TrieST.py because ('EOF in multi-line statement', (193, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/dvklopfenstein.PrincetonAlgorithms/py/AlgsSedgewickWayne/Point2D.py because ('EOF in multi-line statement', (227, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/dvklopfenstein.PrincetonAlgorithms/py/AlgsSedgewickWayne/GREP.py because ('EOF in multi-line statement', (36, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/dvklopfenstein.PrincetonAlgorithms/py/AlgsSedgewickWayne/EdgeWeightedDirectedCycle.py because ('EOF in multi-line statement', (128, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/dvklopfenstein.PrincetonAlgorithms/py/AlgsSedgewickWayne/FordFulkerson.py because ('EOF in multi-line statement', (438, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/dvklopfenstein.PrincetonAlgorithms/py/AlgsSedgewickWayne/BTree.py because ('EOF in multi-line statement', (211, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/dvklopfenstein.PrincetonAlgorithms/py/AlgsSedgewickWayne/RabinKarp.py because ('EOF in multi-line statement', (120, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/dvklopfenstein.PrincetonAlgorithms/py/AlgsSedgewickWayne/Particle.py because ('EOF in multi-line statement', (228, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/dvklopfenstein.PrincetonAlgorithms/py/AlgsSedgewickWayne/DijkstraSP.py because ('EOF in multi-line statement', (128, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/dvklopfenstein.PrincetonAlgorithms/py/AlgsSedgewickWayne/Topological.py because ('EOF in multi-line statement', (51, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/dvklopfenstein.PrincetonAlgorithms/py/AlgsSedgewickWayne/LinkedBag.py because unindent does not match any outer indentation level (<tokenize>, line 84)\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/dvklopfenstein.PrincetonAlgorithms/py/AlgsSedgewickWayne/TarjanSCC.py because ('EOF in multi-line statement', (188, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/dvklopfenstein.PrincetonAlgorithms/py/AlgsSedgewickWayne/NFA.py because ('EOF in multi-line statement', (116, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/dvklopfenstein.PrincetonAlgorithms/py/AlgsSedgewickWayne/LinkedQueue.py because ('EOF in multi-line statement', (181, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/dvklopfenstein.PrincetonAlgorithms/py/AlgsSedgewickWayne/FrequencyCounter.py because ('EOF in multi-line statement', (36, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/dvklopfenstein.PrincetonAlgorithms/py/AlgsSedgewickWayne/SparseVector.py because ('EOF in multi-line statement', (65, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/dvklopfenstein.PrincetonAlgorithms/py/AlgsSedgewickWayne/ThreeSumFast.py because ('EOF in multi-line statement', (156, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/dvklopfenstein.PrincetonAlgorithms/py/AlgsSedgewickWayne/LookupCSV.py because ('EOF in multi-line statement', (34, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/dvklopfenstein.PrincetonAlgorithms/py/AlgsSedgewickWayne/AcyclicLP.py because ('EOF in multi-line statement', (153, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/dvklopfenstein.PrincetonAlgorithms/py/AlgsSedgewickWayne/Whitelist.py because ('EOF in multi-line statement', (88, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/dvklopfenstein.PrincetonAlgorithms/py/AlgsSedgewickWayne/BoyerMoore.py because ('EOF in multi-line statement', (115, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/dvklopfenstein.PrincetonAlgorithms/py/AlgsSedgewickWayne/MSD.py because ('EOF in multi-line statement', (168, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/dvklopfenstein.PrincetonAlgorithms/py/AlgsSedgewickWayne/LinearProgramming.py because ('EOF in multi-line statement', (313, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/dvklopfenstein.PrincetonAlgorithms/py/AlgsSedgewickWayne/TopologicalX.py because ('EOF in multi-line statement', (205, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/dvklopfenstein.PrincetonAlgorithms/py/AlgsSedgewickWayne/CPM.py because ('EOF in multi-line statement', (117, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/dvklopfenstein.PrincetonAlgorithms/py/AlgsSedgewickWayne/SET.py because ('EOF in multi-line statement', (226, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/dvklopfenstein.PrincetonAlgorithms/py/AlgsSedgewickWayne/CollisionSystem.py because ('EOF in multi-line statement', (195, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/dvklopfenstein.PrincetonAlgorithms/py/AlgsSedgewickWayne/ResizingArrayBag.py because ('EOF in multi-line statement', (104, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/dvklopfenstein.PrincetonAlgorithms/py/AlgsSedgewickWayne/GabowSCC.py because ('EOF in multi-line statement', (191, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/dvklopfenstein.PrincetonAlgorithms/py/AlgsSedgewickWayne/BellmanFordSP.py because ('EOF in multi-line statement', (166, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/dvklopfenstein.PrincetonAlgorithms/py/AlgsSedgewickWayne/PrimMST.py because ('EOF in multi-line statement', (159, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/espadrine.opera/chromium/src/third_party/python_26/Lib/test/bad_coding2.py because encoding problem for '/nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/espadrine.opera/chromium/src/third_party/python_26/Lib/test/bad_coding2.py': utf-8\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/espadrine.opera/chromium/src/third_party/python_26/Lib/test/bad_coding.py because unknown encoding for '/nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/espadrine.opera/chromium/src/third_party/python_26/Lib/test/bad_coding.py': uft-8\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/espadrine.opera/chromium/src/third_party/python_26/Lib/site-packages/win32com/test/testGatewayAddresses.py because 'utf-8' codec can't decode byte 0x92 in position 61: invalid start byte\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/espadrine.opera/chromium/src/third_party/mesa/MesaLib/src/gallium/drivers/llvmpipe/lp_tile_shuffle_mask.py because ('EOF in multi-line statement', (33, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/typilus/espadrine.opera/chromium/src/third_party/mesa/src/src/gallium/drivers/llvmpipe/lp_tile_shuffle_mask.py because ('EOF in multi-line statement', (33, 0))\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/cdt4py/numpy/WaiYanLinn10/SFUPython_01/List.py because unindent does not match any outer indentation level (<tokenize>, line 8)\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/cdt4py/numpy/lonelyhentai/impls/data_ai/comp3035/final/multifactor.py because 'utf-8' codec can't decode byte 0xd6 in position 23: invalid continuation byte\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/cdt4py/numpy/gyhd/python_study/paddle_models-develop/PaddleST/Research/KDD2020-P3AC/datasets/poi_qac_personalized/qac_personalized.py because unindent does not match any outer indentation level (<tokenize>, line 164)\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/cdt4py/numpy/erick-marin/Google-ITAutomation-Python/Course_1/Week_3/pratice_quiz_recursion.py because unindent does not match any outer indentation level (<tokenize>, line 82)\n",
      "Error tokenizing /nfs/data/students/bsparks/mdti4py-dataset-pool/cdt4py/numpy/MDSYN2019/MDNPPackage/src/LigandMaker.py because ('EOF in multi-line statement', (41, 0))\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#!cd4py --p /nfs/data/students/bsparks/mdti4py-dataset-pool --ot /nfs/data/students/bsparks/mdti4py-dataset-pool-toks --od /nfs/data/students/bsparks/mdti4py-datasets-dedup\n",
    "\n",
    "# Run in bash shell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "5a25232b-b41f-4c70-bbbf-82654b0974a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce18db0849ac499383b971be0ff8184f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from dpu_utils.utils.dataloading import load_jsonl_gz\n",
    "from libcst import codemod\n",
    "\n",
    "import json, random, collections\n",
    "import pprint\n",
    "\n",
    "# Get size of each project\n",
    "projects_by_size = collections.Counter({\n",
    "    project: len(codemod.gather_files([project]))\n",
    "    for project in tqdm(dataset.project_iter(), total=len(cdt4py_author_repos))\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "51305db5-b159-42b7-9df1-34f13c2a2ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect only cdt4py files\n",
    "cdt4py_clusters = list[dict]()\n",
    "for cluster in load_jsonl_gz(\"/nfs/data/students/bsparks/mdti4py-datasets-dedup/duplicates.jsonl.gz\"):\n",
    "    no_sites = list()\n",
    "    for file in cluster:\n",
    "        if all(forbidden not in file for forbidden in [\"site-packages\", \"Lib\", \"lib\", \"Scripts\"]):\n",
    "            no_sites.append(file)\n",
    "    \n",
    "    pathed = map(pathlib.Path, no_sites)\n",
    "    # print(pathed)\n",
    "    cdt4py_files = list(filter(lambda p: p.is_relative_to(cdt4py_path), pathed))\n",
    "    if not cdt4py_files:\n",
    "        continue\n",
    "\n",
    "    segmented_files = collections.defaultdict[tuple, list](list)\n",
    "    for fpath in cdt4py_files:\n",
    "        from_dataset = fpath.relative_to(cdt4py_path)\n",
    "        category, author, user, *_ = from_dataset.parts\n",
    "        key = (category, author, user)\n",
    "        segmented_files[key].append(fpath)\n",
    "    \n",
    "    cdt4py_clusters.append(segmented_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "2b44140b-3d81-4d8e-8b08-61c42eef2c49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d155dc1d6b4f455f82bad75b2a081378",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8140 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#print(next(iter(projects_by_size)))\n",
    "cdt4py_clusters_wip = cdt4py_clusters[:]\n",
    "cd4py_dedupped = list[pathlib.Path]()\n",
    "\n",
    "for project, _ in tqdm(projects_by_size.most_common(), total=len(projects_by_size)):\n",
    "    from_dataset = project.relative_to(cdt4py_path)\n",
    "    category, author, user, *_ = from_dataset.parts\n",
    "    key = (category, author, user)\n",
    "\n",
    "    redundant = set[int]()\n",
    "    for i, cdt4py_cluster in enumerate(cdt4py_clusters_wip):\n",
    "        if cluster_files := cdt4py_cluster.get(key):\n",
    "            redundant.add(i)\n",
    "            cd4py_dedupped.append(random.choice(cluster_files).relative_to(cdt4py_path))\n",
    "\n",
    "    if redundant:\n",
    "        cdt4py_clusters_wip = [cluster for i, cluster in enumerate(cdt4py_clusters_wip) if i not in redundant]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "b19c212e-43f2-4b09-9c77-97498d0f44a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['numpy/rayhaneHamoumi/arduino/python/DistanceSensor_Python.py', 'numpy/Peipeixuan/muxing-crowdfunding/mainapp/models.py', 'numpy/Peipeixuan/muxing-crowdfunding/proj02/settings.py']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prefix</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>numpy/rayhaneHamoumi/arduino</td>\n",
       "      <td>python/DistanceSensor_Python.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>numpy/Peipeixuan/muxing-crowdfunding</td>\n",
       "      <td>mainapp/models.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>numpy/Peipeixuan/muxing-crowdfunding</td>\n",
       "      <td>proj02/settings.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>numpy/Peipeixuan/muxing-crowdfunding</td>\n",
       "      <td>mainapp/migrations/0005_auto_20200829_1456.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>numpy/Peipeixuan/muxing-crowdfunding</td>\n",
       "      <td>mainapp/migrations/0004_auto_20200829_1442.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>numpy/Peipeixuan/muxing-crowdfunding</td>\n",
       "      <td>manage.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>numpy/Peipeixuan/muxing-crowdfunding</td>\n",
       "      <td>mainapp/migrations/0002_auto_20200824_1438.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>flask/kichappa/QC</td>\n",
       "      <td>mpl_toolkits/axisartist/axisline_style.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>flask/kichappa/QC</td>\n",
       "      <td>pygments/lexers/ncl.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>flask/kichappa/QC</td>\n",
       "      <td>pygments/styles/colorful.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>flask/kichappa/QC</td>\n",
       "      <td>sympy/combinatorics/tests/test_group_construct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>flask/kichappa/QC</td>\n",
       "      <td>sympy/plotting/pygletplot/plot_window.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>flask/kichappa/QC</td>\n",
       "      <td>sqlalchemy/orm/interfaces.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>flask/kichappa/QC</td>\n",
       "      <td>pygments/styles/pastie.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>flask/kichappa/QC</td>\n",
       "      <td>pip/_vendor/chardet/chardistribution.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>flask/kichappa/QC</td>\n",
       "      <td>xlwings/tests/test_sheet.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>flask/kichappa/QC</td>\n",
       "      <td>numba/rewrites/macros.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>flask/kichappa/QC</td>\n",
       "      <td>pip/_vendor/requests/packages.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>flask/kichappa/QC</td>\n",
       "      <td>networkx/algorithms/connectivity/cuts.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>flask/kichappa/QC</td>\n",
       "      <td>sklearn/decomposition/tests/test_online_lda.py</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  prefix                                               file\n",
       "0           numpy/rayhaneHamoumi/arduino                    python/DistanceSensor_Python.py\n",
       "1   numpy/Peipeixuan/muxing-crowdfunding                                  mainapp/models.py\n",
       "2   numpy/Peipeixuan/muxing-crowdfunding                                 proj02/settings.py\n",
       "3   numpy/Peipeixuan/muxing-crowdfunding      mainapp/migrations/0005_auto_20200829_1456.py\n",
       "4   numpy/Peipeixuan/muxing-crowdfunding      mainapp/migrations/0004_auto_20200829_1442.py\n",
       "5   numpy/Peipeixuan/muxing-crowdfunding                                          manage.py\n",
       "6   numpy/Peipeixuan/muxing-crowdfunding      mainapp/migrations/0002_auto_20200824_1438.py\n",
       "7                      flask/kichappa/QC          mpl_toolkits/axisartist/axisline_style.py\n",
       "8                      flask/kichappa/QC                             pygments/lexers/ncl.py\n",
       "9                      flask/kichappa/QC                        pygments/styles/colorful.py\n",
       "10                     flask/kichappa/QC  sympy/combinatorics/tests/test_group_construct...\n",
       "11                     flask/kichappa/QC           sympy/plotting/pygletplot/plot_window.py\n",
       "12                     flask/kichappa/QC                       sqlalchemy/orm/interfaces.py\n",
       "13                     flask/kichappa/QC                          pygments/styles/pastie.py\n",
       "14                     flask/kichappa/QC            pip/_vendor/chardet/chardistribution.py\n",
       "15                     flask/kichappa/QC                        xlwings/tests/test_sheet.py\n",
       "16                     flask/kichappa/QC                           numba/rewrites/macros.py\n",
       "17                     flask/kichappa/QC                   pip/_vendor/requests/packages.py\n",
       "18                     flask/kichappa/QC           networkx/algorithms/connectivity/cuts.py\n",
       "19                     flask/kichappa/QC     sklearn/decomposition/tests/test_online_lda.py"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cd4py_dedupped = list(map(str, cd4py_dedupped))\n",
    "print(cd4py_dedupped[:3])\n",
    "\n",
    "files_by_segment = (\n",
    "    pd.Series(cd4py_dedupped, name=\"file\").str \\\n",
    "    .split(pat=os.sep, n=3, expand=True) \\\n",
    "    .rename(columns=dict(enumerate([\"category\", \"user\", \"repository\", \"file\"])))\n",
    ")\n",
    "files = pd.concat([\n",
    "    files_by_segment[[\"category\", \"user\", \"repository\"]].apply(os.sep.join, axis=1).rename(\"prefix\"),\n",
    "    files_by_segment[\"file\"]\n",
    "], axis=\"columns\")\n",
    "    \n",
    "display(files.head(n=20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "f70e7430-2f87-498a-81fa-d72bb3192962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3582\n",
      "prefix\n",
      "flask/kichappa/QC                  12593\n",
      "numpy/sviete/AIS-home-assistant     4672\n",
      "flask/kfserving/kfserving           2800\n",
      "flask/gyhd/python_study             2296\n",
      "flask/brycepg/pylint-corpus         2040\n",
      "Name: count, dtype: int64\n",
      "129369\n"
     ]
    }
   ],
   "source": [
    "print(files[\"prefix\"].nunique())\n",
    "print(files[\"prefix\"].value_counts().head())\n",
    "print(files[\"prefix\"].value_counts().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "5497d42d-6dee-4108-bc47-a1c448726ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156096\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "weighted = files[\"prefix\"].value_counts(normalize=True).cumsum()\n",
    "validation_repositories, test_repositories = weighted[weighted < 0.8], weighted[weighted >= 0.8]\n",
    "\n",
    "validation_split = files[files[\"prefix\"].isin(validation_repositories.index)]\n",
    "test_split = files[files[\"prefix\"].isin(test_repositories.index)]\n",
    "\n",
    "validation_files = validation_split.apply(os.sep.join, axis=1)\n",
    "test_files = test_split.apply(os.sep.join, axis=1)\n",
    "\n",
    "print(validation_files.shape[0] + test_files.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "f14cc9cf-c552-4791-88ca-7a6e2e943391",
   "metadata": {},
   "outputs": [],
   "source": [
    "with (pathlib.Path(\"/nfs/data/students/bsparks/mdti4py-datasets-dedup\") / \"deduplicated.json\").open(\"w\") as f:\n",
    "    json.dump(cdt4py_dedupped, f)\n",
    "\n",
    "with (pathlib.Path(\"/nfs/data/students/bsparks/mdti4py-datasets-dedup\") / \"validation.json\").open(\"w\") as f:\n",
    "    json.dump(validation_files.tolist(), f)\n",
    "\n",
    "with (pathlib.Path(\"/nfs/data/students/bsparks/mdti4py-datasets-dedup\") / \"test.json\").open(\"w\") as f:\n",
    "    json.dump(test_files.tolist(), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca895602-26c3-40f9-b91d-4cfc9fe9fe71",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = dataset.test_set()\n",
    "print(len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54eadf2f-b54a-46b6-a012-f731cbcceb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_repos = []\n",
    "for cdt4py_repo in (CDT4PyFlaskRepo, CDT4PyNumpyRepo):\n",
    "    downloaded_repos = []\n",
    "    for test_repo in tqdm(test_set, desc=f\"{cdt4py_repo.__qualname__}\"):\n",
    "        repo = cdt4py_repo(dataset.author_repo(test_repo))\n",
    "        if repo.repo_dir(dataset.dataset_root).is_dir():\n",
    "            downloaded_repos.append(repo)\n",
    "\n",
    "    # for r in tqdm.tqdm(downloaded_repos, desc=str(cdt4py_repo)):\n",
    "    #    r.read_last_update(DATA_FOLDER)\n",
    "    \n",
    "    new_domain_repos = [r for r in downloaded_repos if \"typeshed\" not in r.name and \"stub\" not in r.name]\n",
    "    logger.info(f\"{cdt4py_repo.__qualname__}: {len(new_domain_repos)} / {len(downloaded_repos)} are not related to stubbing\")\n",
    "    \n",
    "    new_repos.extend(new_domain_repos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce1867bd6e38b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loc_limit = 50000\n",
    "\n",
    "acceptable_repos = []\n",
    "all_repos = []\n",
    "for rep in tqdm(new_repos):\n",
    "    try:\n",
    "        loc = rep.count_lines_of_code(DATA_FOLDER)\n",
    "        # if loc < loc_limit:\n",
    "        acceptable_repos.append(rep)\n",
    "    except UnicodeDecodeError:\n",
    "        # nothing we can do\n",
    "        logger.warning(f\"{rep.authorname()} does not pass due to encoding error\")\n",
    "    except Exception as e:\n",
    "        logger.warning(f\"{rep.authorname()} does not pass\", exc_info=True)\n",
    "\n",
    "    else:\n",
    "        all_repos.append(rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328a4212-05fb-4319-b046-a65a94265aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"{len(acceptable_repos)}/{len(all_repos)} repos pass readability checks.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69510b67-f390-410e-a3c6-2028bb03b2a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e22e80d4d06d23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_repos = acceptable_repos[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be349d1c84e7ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bin by lines of code\n",
    "import pandas as pd\n",
    "\n",
    "def loc_binning(repos: list[GitRepo], title: str, kloc = loc_limit // 1000) -> None:\n",
    "    LOC_BINS = [loc * 1000 for loc in range(0, kloc + 1, 4)]\n",
    "    repo_loc = pd.DataFrame(\n",
    "        [(repo.authorname(), repo.lines_of_code) for repo in repos],\n",
    "        columns=[\"Repository\", \"Lines of Code\"]\n",
    "    )\n",
    "    repo_loc.plot.hist(ylabel=\"Frequency\", bins=LOC_BINS, title=title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276565ac-c9b8-4918-94c6-7177fc74e907",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(all_repos))\n",
    "loc_binning(all_repos, title=\"All Test Repositories\", kloc = int(1e6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b053240229a5950",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(len(test_repos))\n",
    "loc_binning(test_repos, title=\"Sub 50kLOC Test Repositories\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8316378d6d8b729",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-08T15:08:01.680633868Z",
     "start_time": "2023-08-08T15:08:01.528623889Z"
    }
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "\n",
    "def count_repo_annots(repo: GitRepo) -> tuple[GitRepo, dict] | None:\n",
    "    try:\n",
    "        annotations = repo.collect_annotations(DATA_FOLDER)\n",
    "        if repo.n_type_annots / rep.lines_of_code > 0.05:\n",
    "            return repo, annotations\n",
    "    except Exception:\n",
    "        logger.warning(f\"Failed to count annotations for {repo.name}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9553728711ac611f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "\n",
    "with ProcessPoolExecutor(max_workers=8) as executor:\n",
    "    fs = [executor.submit(count_repo_annots, r) for r in small_repos]\n",
    "    repo2annotations = [f.result() for f in tqdm(as_completed(fs), total=len(fs))]\n",
    "\n",
    "repo2annotations: list[tuple[CDT4PyRepo, dict]] = [r for r in repo2annotations if r is not None]\n",
    "useful_repos: list[CDT4PyRepo] = list(map(operator.itemgetter(0), repo2annotations))\n",
    "\n",
    "logger.info(\n",
    "    f\"{len(useful_repos)}/{len(small_repos)} repos are parsable, have enough portions of type annotations\"\n",
    ")\n",
    "\n",
    "del repo2annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62bf9b453b5b98f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-08T15:07:59.437178798Z",
     "start_time": "2023-08-08T15:07:59.411377044Z"
    }
   },
   "outputs": [],
   "source": [
    "# Bin by relative annotation count\n",
    "def type_slots_filled(repos: list[GitRepo], title: str) -> None:\n",
    "    anno_df = pd.DataFrame(\n",
    "        [(repo.authorname(), repo.n_type_annots / repo.n_type_places * 100) for repo in repos],\n",
    "        columns=[\"Repository\", \"Annotation Frequency\"]\n",
    "    )\n",
    "    bins = [x for x in range(0, 100 + 1, 5)]\n",
    "    anno_df.plot.hist(ylabel=\"Frequency\", bins=bins, title=title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e033f5b4-b756-461f-acd9-4bd18d2d2b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(useful_repos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8cd435519f81fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "type_slots_filled(useful_repos, title=\"Percentile of Type Slots Filled\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
