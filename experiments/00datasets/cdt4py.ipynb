{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-09T11:55:24.391361234Z",
     "start_time": "2023-08-09T11:55:24.349034020Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%pwd\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.expand_frame_repr\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2c4e7858c5f1ad5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-09T11:55:25.853267954Z",
     "start_time": "2023-08-09T11:55:25.839897361Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-18 13:47:57,643 | INFO : Hello World\n"
     ]
    }
   ],
   "source": [
    "import pathlib, sys\n",
    "import logging\n",
    "\n",
    "DATA_FOLDER = pathlib.Path(\"/nfs/data/students/bsparks/mdti4py-dataset-pool/cdt4py/\")\n",
    "assert DATA_FOLDER.is_dir()\n",
    "\n",
    "logger = logging.getLogger(name=__name__)\n",
    "logger.handlers.clear()\n",
    "logger.setLevel(level=logging.DEBUG)\n",
    "\n",
    "handler = logging.StreamHandler(stream=sys.stdout)\n",
    "handler.setFormatter(fmt=logging.Formatter('%(asctime)s | %(levelname)s : %(message)s'))\n",
    "logger.addHandler(handler)\n",
    "\n",
    "logger.info(\"Hello World\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00c2bbbe-3aed-4055-8cf7-7869d22b7330",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-08-09T11:55:27.320208232Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-18 13:48:02.423329: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-18 13:48:03.334403: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-18 13:48:07,255 | DEBUG : CrossDomainTypes4Py @ /nfs/data/students/bsparks/mdti4py-dataset-pool/cdt4py\n"
     ]
    }
   ],
   "source": [
    "from typet5.data import GitRepo\n",
    "from scripts.infer.structure import CrossDomainTypes4Py\n",
    "\n",
    "dataset = CrossDomainTypes4Py(dataset_root=DATA_FOLDER)\n",
    "logger.debug(dataset)\n",
    "\n",
    "\n",
    "\n",
    "from scripts.infer.structure import AuthorRepo\n",
    "from typet5.data import GitRepo\n",
    "\n",
    "\n",
    "class CDT4PyRepo(GitRepo):\n",
    "    def __init__(self, author_repo: AuthorRepo) -> None:\n",
    "        super().__init__(\n",
    "            author=author_repo.author,\n",
    "            name=author_repo.repo,\n",
    "            url=None,\n",
    "            stars=-1,\n",
    "            forks=-1\n",
    "        )\n",
    "\n",
    "class CDT4PyFlaskRepo(CDT4PyRepo):\n",
    "    def repo_dir(self, repos_dir: pathlib.Path) -> pathlib.Path:\n",
    "        return repos_dir / \"flask\" / self.authorname()\n",
    "\n",
    "    def authorname(self) -> str:\n",
    "        assert self.name.startswith(\"flask-\"), f\"Unexpected author: {self.name}\"\n",
    "        return f\"{self.author}/{self.name[6:]}\"\n",
    "    \n",
    "class CDT4PyNumpyRepo(CDT4PyRepo):\n",
    "    def repo_dir(self, repos_dir: pathlib.Path) -> pathlib.Path:\n",
    "        return repos_dir / \"numpy\" / self.authorname()\n",
    "\n",
    "    def authorname(self) -> str:\n",
    "        assert self.name.startswith(\"numpy-\"), f\"Unexpected author: {self.name}\"\n",
    "        return f\"{self.author}/{self.name[6:]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebbb9c54-e301-4dd9-9f47-2f3d68960297",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8140"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cdt4py_author_repos: dict[AuthorRepo, pathlib.Path] = {\n",
    "    dataset.author_repo(repository): repository\n",
    "    for repository in dataset.project_iter()\n",
    "}\n",
    "display(len(cdt4py_author_repos))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ab3252-d821-4313-9210-745303790651",
   "metadata": {},
   "source": [
    "# Remove BetterTypes4Py, Typilus and Type4Py datasets from CrossDomainTypes4Py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7961ec15-bb08-436d-9000-7bc90763b1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install cd4py\n",
    "#!pip install \"typing_extensions==4.5.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6294c6-c5cb-4ff6-ae0e-1c1a06a1f4a1",
   "metadata": {},
   "source": [
    "Number of source code files: 2,604,611                                                                                \n",
    "[I 2023-09-07 14:03:50.700 ServerApp] Saving file at /experiments/00datasets/cdt4py.ipynb                            │Total number of tokens: 1,268,703,455                                                                                 \n",
    "[I 2023-09-07 14:05:50.926 ServerApp] Saving file at /experiments/00datasets/cdt4py.ipynb                            │100%|█████████████████████████████████████████████████████████████████████| 2604611/2604611 [05:56<00:00, 7315.22it/s]\n",
    "[W 2023-09-07 17:52:42.791 ServerApp] WebSocket ping timeout after 119980 ms.                                        │100%|█████████████████████████████████████████████████████████████████████| 2604611/2604611 [12:04<00:00, 3596.45it/s]\n",
    "[I 2023-09-07 17:52:47.792 ServerApp] Starting buffering for 86de0c3c-afd7-4dac-bf0d-24991e3d37cb:2196c57f-60da-4220-│***********************Vectorize pre-processed source code files using TF-IDF**********************                   \n",
    "8563-671aa53816b7                                                                                                    │100%|█████████████████████████████████████████████████████████████████████| 2604611/2604611 [21:26<00:00, 2023.87it/s]\n",
    "[I 2023-09-08 17:42:51.424 ServerApp] 302 GET / (@127.0.0.1) 0.92ms                                                  │**************************Building KNN index and finding nearest neighbors*************************                   \n",
    "[W 2023-09-08 17:42:53.855 LabApp] Could not determine jupyterlab build status without nodejs                        │100%|█████████████████████████████████████████████████████████████████████| 2604611/2604611 [05:55<00:00, 7336.19it/s]\n",
    "[I 2023-09-08 17:42:54.006 ServerApp] Connecting to kernel cf8cb073-e5b3-4c1c-b385-c6ccc37efb55.                     │100%|██████████████████████████████████████████████████████████████████████| 2604611/2604611 [50:09<00:00, 865.38it/s]\n",
    "[I 2023-09-08 17:42:54.058 ServerApp] Connecting to kernel 9fc37da9-cbb6-4566-928d-99f2fee6a601.                     │*******************************Finding exact and near duplicate files******************************                   \n",
    "[I 2023-09-08 17:42:54.097 ServerApp] Connecting to kernel 86de0c3c-afd7-4dac-bf0d-24991e3d37cb.                     │100%|█████████████████████████████████████████████████████████████████████| 2604611/2604611 [07:46<00:00, 5580.31it/s]\n",
    "[I 2023-09-08 17:42:54.332 ServerApp] Starting buffering for cf8cb073-e5b3-4c1c-b385-c6ccc37efb55:fc69da8c-75c8-4c77-│*********************Report duplication stats & saving detected duplicate files********************                   \n",
    "9f70-ba2e4aa42f86                                                                                                    │Number of duplicated files: 2,417,250 (92.81%)                                                                        \n",
    "[I 2023-09-08 17:42:54.333 ServerApp] Starting buffering for 9fc37da9-cbb6-4566-928d-99f2fee6a601:c7f7880b-5671-4bba-│Number of detected clusters: 184,937                                                                                  \n",
    "be2d-b039572025d3                                                                                                    │Avg. number of files per clones: 13.07                                                                                \n",
    "[I 2023-09-08 17:42:54.334 ServerApp] Starting buffering for 86de0c3c-afd7-4dac-bf0d-24991e3d37cb:3b942345-73e7-49ea-│Median number of files per clones: 4.00                                                                               \n",
    "81d8-45e8e8e83e92                                                                                                    │Duplication ratio: 85.71%                                                                                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b983a1ed-9ba8-41fd-b6f2-85805454ecd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: cd4py [-h] --p P --od OD --ot OT [--d D] [--th TH] [--k K] [--tr TR]\n",
      "\n",
      "Code De-Duplication for Python\n",
      "\n",
      "options:\n",
      "  -h, --help  show this help message and exit\n",
      "  --p P       Path to Python projects\n",
      "  --od OD     Output folder to store detected duplicate files.\n",
      "  --ot OT     Output folder to store tokenized files.\n",
      "  --d D       Dimension of TF-IDF vectors [default: 2048].\n",
      "  --th TH     Threshold to identify duplicate files [default: 0.95].\n",
      "  --k K       Number of nearest neighbor [default: 10].\n",
      "  --tr TR     Number trees to build the index. More trees gives higher\n",
      "              precision but slower [default: 20].\n"
     ]
    }
   ],
   "source": [
    "!cd4py --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba7b41e0-abba-43d8-960f-4926cf6971c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 2 µs, total: 4 µs\n",
      "Wall time: 9.06 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#!cd4py --p /nfs/data/students/bsparks/mdti4py-dataset-pool --ot /nfs/data/students/bsparks/mdti4py-dataset-pool-toks --od /nfs/data/students/bsparks/mdti4py-datasets-dedup\n",
    "\n",
    "# Run in bash shell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a25232b-b41f-4c70-bbbf-82654b0974a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1009cbd47cc441aa2d42f7cb23ca05c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8140 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from dpu_utils.utils.dataloading import load_jsonl_gz\n",
    "from libcst import codemod\n",
    "\n",
    "import json, random, collections\n",
    "import pprint\n",
    "\n",
    "# Get size of each project\n",
    "projects_by_size = collections.Counter({\n",
    "    project: len(codemod.gather_files([project]))\n",
    "    for project in tqdm(dataset.project_iter(), total=len(cdt4py_author_repos))\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec7dc398-0818-4170-9697-522dedc0daf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c30f6bfbfb64319bb87e09ca45973c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8140 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "name              \n",
       "home-assistant        135\n",
       "incubator-superset     61\n",
       "Python                 59\n",
       "pandas                 45\n",
       "allennlp               43\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict({\n",
    "    \"name\": [project.name for project in tqdm(dataset.project_iter(), total=len(cdt4py_author_repos))]\n",
    "})\n",
    "\n",
    "display(df.value_counts().head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51305db5-b159-42b7-9df1-34f13c2a2ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect only cdt4py files\n",
    "cdt4py_clusters = list[dict]()\n",
    "cdt4py_path = pathlib.Path(\"/nfs/data/students/bsparks/mdti4py-dataset-pool/cdt4py\")\n",
    "for cluster in load_jsonl_gz(\"/nfs/data/students/bsparks/mdti4py-datasets-dedup/duplicates.jsonl.gz\"):\n",
    "    no_sites = list()\n",
    "    for file in cluster:\n",
    "        if all(forbidden not in file.lower() for forbidden in [\"venv\", \"site-packages\", \"lib\", \"scripts\"]):\n",
    "            no_sites.append(file)\n",
    "    \n",
    "    pathed = map(pathlib.Path, no_sites)\n",
    "    # print(pathed)\n",
    "    cdt4py_files = list(filter(lambda p: p.is_relative_to(cdt4py_path), pathed))\n",
    "    if not cdt4py_files:\n",
    "        continue\n",
    "\n",
    "    segmented_files = collections.defaultdict[tuple, list](list)\n",
    "    for fpath in cdt4py_files:\n",
    "        from_dataset = fpath.relative_to(cdt4py_path)\n",
    "        category, author, user, *_ = from_dataset.parts\n",
    "        key = (category, author, user)\n",
    "        segmented_files[key].append(fpath)\n",
    "    \n",
    "    cdt4py_clusters.append(segmented_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b44140b-3d81-4d8e-8b08-61c42eef2c49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9b1d1c3384445c0b6035edf85a61f3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8140 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#print(next(iter(projects_by_size)))\n",
    "cdt4py_clusters_wip = cdt4py_clusters[:]\n",
    "cdt4py_dedupped = list[pathlib.Path]()\n",
    "\n",
    "vendored = {\n",
    "    (\"flask\", \"kichappa\", \"QC\"),\n",
    "    (\"numpy\", \"kichappa\", \"QC\"),\n",
    "}\n",
    "\n",
    "for project, _ in tqdm(projects_by_size.most_common(), total=len(projects_by_size)):\n",
    "    from_dataset = project.relative_to(cdt4py_path)\n",
    "    category, author, user, *_ = from_dataset.parts\n",
    "    key = (category, author, user)\n",
    "    if key in vendored:\n",
    "        continue\n",
    "\n",
    "    redundant = set[int]()\n",
    "    for i, cdt4py_cluster in enumerate(cdt4py_clusters_wip):\n",
    "        if cluster_files := cdt4py_cluster.get(key):\n",
    "            redundant.add(i)\n",
    "            cdt4py_dedupped.append(random.choice(cluster_files).relative_to(cdt4py_path))\n",
    "\n",
    "    if redundant:\n",
    "        cdt4py_clusters_wip = [cluster for i, cluster in enumerate(cdt4py_clusters_wip) if i not in redundant]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b19c212e-43f2-4b09-9c77-97498d0f44a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['numpy/rayhaneHamoumi/arduino/python/TemperatureSensor_Python.py', 'numpy/Peipeixuan/muxing-crowdfunding/mainapp/migrations/0003_auto_20200829_1246.py', 'numpy/Peipeixuan/muxing-crowdfunding/proj02/settings.py']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prefix</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>numpy/rayhaneHamoumi/arduino</td>\n",
       "      <td>python/TemperatureSensor_Python.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>numpy/Peipeixuan/muxing-crowdfunding</td>\n",
       "      <td>mainapp/migrations/0003_auto_20200829_1246.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>numpy/Peipeixuan/muxing-crowdfunding</td>\n",
       "      <td>proj02/settings.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>numpy/Peipeixuan/muxing-crowdfunding</td>\n",
       "      <td>mainapp/migrations/0005_auto_20200829_1456.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>numpy/Peipeixuan/muxing-crowdfunding</td>\n",
       "      <td>mainapp/migrations/0004_auto_20200829_1442.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>numpy/Peipeixuan/muxing-crowdfunding</td>\n",
       "      <td>manage.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>numpy/Peipeixuan/muxing-crowdfunding</td>\n",
       "      <td>mainapp/migrations/0002_auto_20200824_1438.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>flask/danfordshadrack/ulanga-dash</td>\n",
       "      <td>script.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>flask/danfordshadrack/ulanga-dash</td>\n",
       "      <td>main.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>flask/jovanglig/Disaster_Response_App</td>\n",
       "      <td>app/run.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>flask/jovanglig/Disaster_Response_App</td>\n",
       "      <td>models/train_classifier.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>flask/jovanglig/Disaster_Response_App</td>\n",
       "      <td>data/process_data.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>numpy/Beomsudev/Git</td>\n",
       "      <td>DAY01/A/제01일차/variable2.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>numpy/Beomsudev/Git</td>\n",
       "      <td>DAY02/A/제02일차/dictExam01.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>numpy/Beomsudev/Git</td>\n",
       "      <td>DAY10/A/제10일차/arrayDimShape.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>numpy/Beomsudev/Git</td>\n",
       "      <td>DAY05/P2/02_osTest02.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>numpy/Beomsudev/Git</td>\n",
       "      <td>자료/제13일차/wineCheckStop.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>numpy/Beomsudev/Git</td>\n",
       "      <td>DAY10/P1/12_dataframeGraph02.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>numpy/Beomsudev/Git</td>\n",
       "      <td>DAY07/A/제07일차/xmlEx02.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>numpy/Beomsudev/Git</td>\n",
       "      <td>DAY05/A/naverCartoon.py</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   prefix                                           file\n",
       "0            numpy/rayhaneHamoumi/arduino             python/TemperatureSensor_Python.py\n",
       "1    numpy/Peipeixuan/muxing-crowdfunding  mainapp/migrations/0003_auto_20200829_1246.py\n",
       "2    numpy/Peipeixuan/muxing-crowdfunding                             proj02/settings.py\n",
       "3    numpy/Peipeixuan/muxing-crowdfunding  mainapp/migrations/0005_auto_20200829_1456.py\n",
       "4    numpy/Peipeixuan/muxing-crowdfunding  mainapp/migrations/0004_auto_20200829_1442.py\n",
       "5    numpy/Peipeixuan/muxing-crowdfunding                                      manage.py\n",
       "6    numpy/Peipeixuan/muxing-crowdfunding  mainapp/migrations/0002_auto_20200824_1438.py\n",
       "7       flask/danfordshadrack/ulanga-dash                                      script.py\n",
       "8       flask/danfordshadrack/ulanga-dash                                        main.py\n",
       "9   flask/jovanglig/Disaster_Response_App                                     app/run.py\n",
       "10  flask/jovanglig/Disaster_Response_App                     models/train_classifier.py\n",
       "11  flask/jovanglig/Disaster_Response_App                           data/process_data.py\n",
       "12                    numpy/Beomsudev/Git                     DAY01/A/제01일차/variable2.py\n",
       "13                    numpy/Beomsudev/Git                    DAY02/A/제02일차/dictExam01.py\n",
       "14                    numpy/Beomsudev/Git                 DAY10/A/제10일차/arrayDimShape.py\n",
       "15                    numpy/Beomsudev/Git                        DAY05/P2/02_osTest02.py\n",
       "16                    numpy/Beomsudev/Git                      자료/제13일차/wineCheckStop.py\n",
       "17                    numpy/Beomsudev/Git                DAY10/P1/12_dataframeGraph02.py\n",
       "18                    numpy/Beomsudev/Git                       DAY07/A/제07일차/xmlEx02.py\n",
       "19                    numpy/Beomsudev/Git                        DAY05/A/naverCartoon.py"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(117145, 2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "cdt4py_dedupped = list(map(str, cdt4py_dedupped))\n",
    "print(cdt4py_dedupped[:3])\n",
    "\n",
    "files_by_segment = (\n",
    "    pd.Series(cdt4py_dedupped, name=\"file\").str \\\n",
    "    .split(pat=os.sep, n=3, expand=True) \\\n",
    "    .rename(columns=dict(enumerate([\"category\", \"user\", \"repository\", \"file\"])))\n",
    ")\n",
    "files = pd.concat([\n",
    "    files_by_segment[[\"category\", \"user\", \"repository\"]].apply(os.sep.join, axis=1).rename(\"prefix\"),\n",
    "    files_by_segment[\"file\"]\n",
    "], axis=\"columns\")\n",
    "    \n",
    "display(files.head(n=20), files.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f70e7430-2f87-498a-81fa-d72bb3192962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "projects: 3566\n",
      "largest projects: prefix\n",
      "numpy/sviete/AIS-home-assistant    4661\n",
      "flask/kfserving/kfserving          2797\n",
      "flask/brycepg/pylint-corpus        2571\n",
      "flask/gyhd/python_study            2277\n",
      "numpy/Pandinosaurus/airflow        1746\n",
      "Name: count, dtype: int64\n",
      "file count: 117145\n"
     ]
    }
   ],
   "source": [
    "print(\"projects:\", files[\"prefix\"].nunique())\n",
    "print(\"largest projects:\", files[\"prefix\"].value_counts().head())\n",
    "print(\"file count:\", files[\"prefix\"].value_counts().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27ec3ad-2d3f-4e4d-9db3-8b8dc6dce09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(files[\"prefix\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54eadf2f-b54a-46b6-a012-f731cbcceb86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cdd72fdbccd4ed380a1547a4b69b9b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3566 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-18 13:56:00,835 | INFO : Selected 3566 projects\n"
     ]
    }
   ],
   "source": [
    "new_repos = []\n",
    "\n",
    "for repository in tqdm(files[\"prefix\"].unique()):\n",
    "    test_repo_path = cdt4py_path / repository\n",
    "    if repository.startswith(\"numpy/\"):\n",
    "        repo = CDT4PyNumpyRepo(dataset.author_repo(test_repo_path))\n",
    "    elif repository.startswith(\"flask/\"):\n",
    "        repo = CDT4PyFlaskRepo(dataset.author_repo(test_repo_path))\n",
    "    else:\n",
    "        assert False, f\"Unknown prefix: {repository}\" \n",
    "    d = repo.repo_dir(cdt4py_path)\n",
    "    if d.is_dir():\n",
    "        new_repos.append(repo)\n",
    "\n",
    "    # for r in tqdm.tqdm(downloaded_repos, desc=str(cdt4py_repo)):\n",
    "    #    r.read_last_update(DATA_FOLDER)\n",
    "logger.info(f\"Selected {len(new_repos)} projects\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ce1867bd6e38b3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab14fb26ba4342b0839e89f127501f74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3566 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-18 13:56:02,990 | WARNING : rayhaneHamoumi/arduino does not pass due to encoding error\n",
      "2023-09-18 13:56:04,700 | WARNING : Peipeixuan/muxing-crowdfunding does not pass due to encoding error\n",
      "2023-09-18 13:56:11,209 | WARNING : jovanglig/Disaster_Response_App does not pass due to encoding error\n",
      "2023-09-18 13:56:14,042 | WARNING : Beomsudev/Git does not pass due to encoding error\n",
      "2023-09-18 13:56:15,247 | WARNING : garikapatisravani/PythonDeepLearning does not pass due to encoding error\n",
      "2023-09-18 13:56:17,074 | WARNING : dasanchez11/dog-breed does not pass due to encoding error\n",
      "2023-09-18 13:56:18,684 | WARNING : cryptowhaler/ISC-POC does not pass due to encoding error\n",
      "2023-09-18 13:56:21,973 | WARNING : Anubha-Singh/Disease-Mortality-Prediction does not pass due to encoding error\n",
      "2023-09-18 13:56:22,749 | WARNING : iron-condor/MLSR-LTC does not pass due to encoding error\n",
      "2023-09-18 13:56:24,720 | WARNING : autist47/MusicToNotes does not pass due to encoding error\n",
      "2023-09-18 13:56:28,874 | WARNING : Ouroboros/JuusanKoubou does not pass due to encoding error\n",
      "2023-09-18 13:56:30,399 | WARNING : JvstinNgvyen/pythonGame does not pass due to encoding error\n",
      "2023-09-18 13:56:31,589 | WARNING : NateWeiler/Resources does not pass due to encoding error\n",
      "2023-09-18 13:56:32,919 | WARNING : themightyNJ/ml-car-price-calculator does not pass due to encoding error\n",
      "2023-09-18 13:56:34,526 | WARNING : TradingInfrastructure/WalkForwardBacktrader does not pass due to encoding error\n",
      "2023-09-18 13:56:35,929 | WARNING : sauravsrijan/py38-test does not pass due to encoding error\n",
      "2023-09-18 13:56:42,076 | WARNING : sawdeepa/Textract does not pass due to encoding error\n",
      "2023-09-18 13:56:43,533 | WARNING : 500ping/bnk-trainning does not pass due to encoding error\n",
      "2023-09-18 13:56:44,895 | WARNING : jayant4/deploy_test_2 does not pass due to encoding error\n",
      "2023-09-18 13:57:19,518 | WARNING : Assaye/s14alab2 does not pass due to encoding error\n",
      "2023-09-18 13:57:31,726 | WARNING : MDSYN2019/Chemiinformatics_work does not pass due to encoding error\n",
      "2023-09-18 13:57:40,025 | WARNING : WeilerWebServices/Termux does not pass due to encoding error\n",
      "2023-09-18 13:57:48,305 | WARNING : Honeson/Sentiment_Analyzer does not pass due to encoding error\n",
      "2023-09-18 13:57:58,799 | WARNING : tonyliunyc/s14lab3 does not pass due to encoding error\n",
      "2023-09-18 13:57:59,955 | WARNING : tonyliunyc/s14lab2 does not pass due to encoding error\n",
      "2023-09-18 13:58:30,204 | WARNING : JuanRuizB/Recop does not pass due to encoding error\n",
      "2023-09-18 13:58:33,828 | WARNING : vijikrish-or/tsfore does not pass due to encoding error\n",
      "2023-09-18 13:58:44,707 | WARNING : maxbutyaev/review_rating does not pass due to encoding error\n",
      "2023-09-18 13:58:51,625 | WARNING : ShrutiMyIdeasMyBlogs/tutorial4 does not pass due to encoding error\n",
      "2023-09-18 13:58:55,982 | WARNING : mgilli360/spotify_mini_project does not pass due to encoding error\n",
      "2023-09-18 13:58:57,662 | WARNING : faiz-hasan11/DiaBity does not pass due to encoding error\n",
      "2023-09-18 13:58:58,738 | WARNING : moncykurien/EmployeeChurn_EndToEnd_v1 does not pass due to encoding error\n",
      "2023-09-18 13:59:03,519 | WARNING : faiz-hasan11/Health-Hack does not pass due to encoding error\n",
      "2023-09-18 13:59:07,320 | WARNING : ullas22/ML-project does not pass due to encoding error\n",
      "2023-09-18 13:59:19,758 | WARNING : b18050/estip does not pass due to encoding error\n",
      "2023-09-18 13:59:20,755 | WARNING : PavanRaghavendraKulkarni/Flight-Air-Fair-Prediction does not pass due to encoding error\n",
      "2023-09-18 13:59:31,176 | WARNING : relfarizi/NLP-Chatbot does not pass due to encoding error\n",
      "2023-09-18 13:59:35,005 | WARNING : udit1707/FlaskBasedRecommenderSystem does not pass due to encoding error\n",
      "2023-09-18 13:59:39,473 | WARNING : sydney-runkle/COVIDCast-Testing-Data does not pass due to encoding error\n",
      "2023-09-18 13:59:43,016 | WARNING : lmt20/clasify_images_api does not pass due to encoding error\n",
      "2023-09-18 13:59:43,896 | WARNING : ajin513/AJIN-IPL-SCORE-PREDICTOR does not pass due to encoding error\n",
      "2023-09-18 13:59:46,533 | WARNING : littlemall/littlemall-backend-sql does not pass due to encoding error\n",
      "2023-09-18 13:59:47,325 | WARNING : ayumitanaka13/microblog does not pass due to encoding error\n",
      "2023-09-18 13:59:48,150 | WARNING : Ninotd/sound_app does not pass due to encoding error\n",
      "2023-09-18 13:59:49,552 | WARNING : oana-hriscu/pcd-hw2 does not pass due to encoding error\n",
      "2023-09-18 13:59:54,579 | WARNING : kyro-dev/Quasar-Project does not pass due to encoding error\n",
      "2023-09-18 13:59:55,438 | WARNING : raffaelluna/deploy-churn-project does not pass due to encoding error\n",
      "2023-09-18 13:59:56,287 | WARNING : srdhr1234/HeartDiseaseDemo does not pass due to encoding error\n",
      "2023-09-18 14:00:05,777 | WARNING : harrison2687/ml-project does not pass due to encoding error\n",
      "2023-09-18 14:00:06,551 | WARNING : jahonis123/coordster-app does not pass due to encoding error\n",
      "2023-09-18 14:00:08,067 | WARNING : alexsaake/BA does not pass due to encoding error\n",
      "2023-09-18 14:00:14,671 | WARNING : brycepg/pylint-corpus does not pass due to encoding error\n",
      "2023-09-18 14:00:15,286 | WARNING : brycepg/pylint-corpus does not pass due to encoding error\n",
      "2023-09-18 14:00:15,530 | WARNING : dineshkumarkb/MyPractice does not pass due to encoding error\n",
      "2023-09-18 14:00:18,486 | WARNING : xmy0916/EuroTruckSelfDriver does not pass due to encoding error\n",
      "2023-09-18 14:00:19,439 | WARNING : pedrogrijalva-uio/flask-training does not pass due to encoding error\n",
      "2023-09-18 14:00:23,169 | WARNING : SJHH-Nguyen-D/Diving-Into-Python-with-Corey-Schafer does not pass\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_2730048/2885536636.py\", line 7, in <module>\n",
      "    loc = rep.count_lines_of_code(DATA_FOLDER)\n",
      "  File \"/nfs/home/bsparks/.conda/envs/poetry/lib/python3.10/site-packages/typet5/data.py\", line 95, in count_lines_of_code\n",
      "    with open(src, \"r\") as fp:\n",
      "IsADirectoryError: [Errno 21] Is a directory: '/nfs/data/students/bsparks/mdti4py-dataset-pool/cdt4py/flask/SJHH-Nguyen-D/Diving-Into-Python-with-Corey-Schafer/PM_damage_calculator.py'\n",
      "2023-09-18 14:00:23,740 | WARNING : shenlab-ucsf/SMART-Q does not pass due to encoding error\n",
      "2023-09-18 14:00:26,699 | WARNING : PavanRaghavendraKulkarni/Fruit-prediction does not pass due to encoding error\n",
      "2023-09-18 14:00:28,332 | WARNING : M4THYOU/jbsV0.001 does not pass due to encoding error\n",
      "2023-09-18 14:00:29,768 | WARNING : LukazDane/eb-flask does not pass due to encoding error\n",
      "2023-09-18 14:00:31,502 | WARNING : DevleenaBanerjee/Tweet-emotion-detection-heroku-app does not pass due to encoding error\n",
      "2023-09-18 14:00:35,339 | WARNING : alexboy60318/project_NLP does not pass due to encoding error\n",
      "2023-09-18 14:00:36,377 | WARNING : abdessamad-ca/lr_flask_with_bdd does not pass due to encoding error\n",
      "2023-09-18 14:00:40,550 | WARNING : abhishekkpandey1/Flask-Deployment does not pass due to encoding error\n",
      "2023-09-18 14:00:43,754 | WARNING : jaikrish5/football_gcp does not pass due to encoding error\n",
      "2023-09-18 14:00:46,323 | WARNING : whenitapproaches/vieclamcntt-analytics does not pass due to encoding error\n",
      "2023-09-18 14:00:56,176 | WARNING : Awannaphasch2016/FAUCovid19 does not pass due to encoding error\n",
      "2023-09-18 14:01:11,570 | WARNING : guojl7/MachineLearning_test does not pass due to encoding error\n",
      "2023-09-18 14:01:11,584 | WARNING : guojl7/MachineLearning_test does not pass due to encoding error\n",
      "2023-09-18 14:01:14,953 | WARNING : ykchen12/UserCenter does not pass due to encoding error\n",
      "2023-09-18 14:01:15,965 | WARNING : thomasm1/python_2018 does not pass due to encoding error\n",
      "2023-09-18 14:01:21,971 | WARNING : sirinenisaikiran/Python does not pass due to encoding error\n",
      "2023-09-18 14:01:42,451 | WARNING : vietnamz/kineteco-research does not pass due to encoding error\n",
      "2023-09-18 14:01:44,933 | WARNING : drmingdrmer/homefolder does not pass due to encoding error\n",
      "2023-09-18 14:01:46,616 | WARNING : daorenfeixueyuhua/SRC does not pass due to encoding error\n",
      "2023-09-18 14:01:50,852 | WARNING : lambdanerd/CodingDojo does not pass due to encoding error\n",
      "2023-09-18 14:02:12,082 | WARNING : huoweikong/python_pch_kiton does not pass due to encoding error\n",
      "2023-09-18 14:02:13,782 | WARNING : yogeshhk/TeachingDataScience does not pass due to encoding error\n",
      "2023-09-18 14:02:26,354 | WARNING : JackMcKew/jackmckew.dev does not pass due to encoding error\n",
      "2023-09-18 14:02:28,911 | WARNING : binderclip/code-snippets-python does not pass due to encoding error\n",
      "2023-09-18 14:02:29,223 | WARNING : yishenggudou/blog does not pass due to encoding error\n",
      "2023-09-18 14:02:40,569 | WARNING : Julian/streamlit does not pass\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_2730048/2885536636.py\", line 7, in <module>\n",
      "    loc = rep.count_lines_of_code(DATA_FOLDER)\n",
      "  File \"/nfs/home/bsparks/.conda/envs/poetry/lib/python3.10/site-packages/typet5/data.py\", line 95, in count_lines_of_code\n",
      "    with open(src, \"r\") as fp:\n",
      "IsADirectoryError: [Errno 21] Is a directory: '/nfs/data/students/bsparks/mdti4py-dataset-pool/cdt4py/numpy/Julian/streamlit/frontend/cypress/snapshots/linux/2x/st_empty.py'\n",
      "2023-09-18 14:02:47,058 | WARNING : huamichaelchen/streamlit does not pass\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_2730048/2885536636.py\", line 7, in <module>\n",
      "    loc = rep.count_lines_of_code(DATA_FOLDER)\n",
      "  File \"/nfs/home/bsparks/.conda/envs/poetry/lib/python3.10/site-packages/typet5/data.py\", line 95, in count_lines_of_code\n",
      "    with open(src, \"r\") as fp:\n",
      "IsADirectoryError: [Errno 21] Is a directory: '/nfs/data/students/bsparks/mdti4py-dataset-pool/cdt4py/numpy/huamichaelchen/streamlit/frontend/cypress/snapshots/linux/2x/st_empty.py'\n",
      "2023-09-18 14:03:05,420 | WARNING : sklonely/python does not pass due to encoding error\n",
      "2023-09-18 14:03:24,967 | WARNING : lonelyhentai/impls does not pass due to encoding error\n",
      "2023-09-18 14:03:25,233 | WARNING : pondelion/FinAppBackend does not pass\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_2730048/2885536636.py\", line 7, in <module>\n",
      "    loc = rep.count_lines_of_code(DATA_FOLDER)\n",
      "  File \"/nfs/home/bsparks/.conda/envs/poetry/lib/python3.10/site-packages/typet5/data.py\", line 95, in count_lines_of_code\n",
      "    with open(src, \"r\") as fp:\n",
      "IsADirectoryError: [Errno 21] Is a directory: '/nfs/data/students/bsparks/mdti4py-dataset-pool/cdt4py/numpy/pondelion/FinAppBackend/fin_app/crawler/economic_indicators/exchange.py'\n",
      "2023-09-18 14:03:28,356 | WARNING : moinahmed001/roku-config does not pass due to encoding error\n",
      "2023-09-18 14:03:34,791 | WARNING : abdullahmitkar/fall2019-nlp does not pass due to encoding error\n",
      "2023-09-18 14:03:35,892 | WARNING : MonetDBSolutions/MonetDBe-Python does not pass due to encoding error\n",
      "2023-09-18 14:03:44,167 | WARNING : SuLaePhyuSin/SFUpython does not pass\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_2730048/2885536636.py\", line 7, in <module>\n",
      "    loc = rep.count_lines_of_code(DATA_FOLDER)\n",
      "  File \"/nfs/home/bsparks/.conda/envs/poetry/lib/python3.10/site-packages/typet5/data.py\", line 95, in count_lines_of_code\n",
      "    with open(src, \"r\") as fp:\n",
      "IsADirectoryError: [Errno 21] Is a directory: '/nfs/data/students/bsparks/mdti4py-dataset-pool/cdt4py/numpy/SuLaePhyuSin/SFUpython/game.py'\n",
      "2023-09-18 14:03:47,414 | WARNING : pawlaczyk/UAM_graf does not pass due to encoding error\n",
      "2023-09-18 14:03:52,905 | WARNING : DivisionBy-Zero/erpa-sweng does not pass due to encoding error\n"
     ]
    }
   ],
   "source": [
    "loc_limit = 50000\n",
    "\n",
    "acceptable_repos = []\n",
    "all_repos = []\n",
    "for rep in tqdm(new_repos):\n",
    "    try:\n",
    "        loc = rep.count_lines_of_code(DATA_FOLDER)\n",
    "        if loc < loc_limit:\n",
    "            acceptable_repos.append(rep)\n",
    "    except UnicodeDecodeError:\n",
    "        # nothing we can do\n",
    "        logger.warning(f\"{rep.authorname()} does not pass due to encoding error\")\n",
    "    except Exception as e:\n",
    "        logger.warning(f\"{rep.authorname()} does not pass\", exc_info=True)\n",
    "\n",
    "    else:\n",
    "        all_repos.append(rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8d6bbcdd-1f2f-4ea7-9c04-8fb96d11c4c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16c09966133748c08ef065ead9f46d9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2907 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "name              \n",
       "Python                13\n",
       "openpilot             11\n",
       "allennlp               9\n",
       "incubator-superset     8\n",
       "PySyft                 5\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict({\n",
    "    \"name\": [repo.name[6:] for repo in tqdm(acceptable_repos, total=len(acceptable_repos))]\n",
    "})\n",
    "\n",
    "display(df.value_counts().head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "328a4212-05fb-4319-b046-a65a94265aff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2907/3473 repos pass readability checks.\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"{len(acceptable_repos)}/{len(all_repos)} repos pass readability and LOC checks.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7ba294d0-b6aa-49ec-8695-8bc1f9276834",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "def count_repo_annots(rep: CDT4PyRepo) -> tuple[CDT4PyRepo, dict] | None:\n",
    "    try:\n",
    "        annotations = rep.collect_annotations(DATA_FOLDER, silent=True)\n",
    "        if rep.n_type_annots / rep.lines_of_code >= 0.02:\n",
    "            return rep, annotations\n",
    "    except Exception as e:\n",
    "        #logger.warning(f\"Failed to count annotations for {rep.name}. Exception: {e}\")\n",
    "        return None\n",
    "\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "\n",
    "with ProcessPoolExecutor(max_workers=64) as executor:\n",
    "    fs = [executor.submit(count_repo_annots, r) for r in acceptable_repos]\n",
    "    repo2annotations = [f.result() for f in tqdm(as_completed(fs), total=len(fs))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827635dc-d082-4a85-bb98-64c866e8660f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e18fa5b4-9544-4b09-ac1f-cb5676894219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-19 11:38:23,927 | INFO : 1553/2907 repos are parsable, have enough portions of type annotations\n"
     ]
    }
   ],
   "source": [
    "import operator\n",
    "\n",
    "repo2annotations: list[tuple[CDT4PyRepo, dict]] = [r for r in repo2annotations if r is not None]\n",
    "useful_repos: list[CDT4PyRepo] = list(map(operator.itemgetter(0), repo2annotations))\n",
    "\n",
    "logger.info(\n",
    "    f\"{len(useful_repos)}/{len(acceptable_repos)} repos are parsable, have enough portions of type annotations\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ee728eba-ee99-4695-a508-7b6cbcf1a12c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['numpy/Tony-Starkus/udemy-course-guppe', 'flask/uniwue-it4all/it4all-resources', 'numpy/nickderobertis/py-ex-latex']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "26957"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1553"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "useful_repo_names = []\n",
    "for repo in useful_repos:\n",
    "    useful_repo_names.append(f\"{repo.name[:5]}/{repo.author}/{repo.name[6:]}\")\n",
    "print(useful_repo_names[:3])\n",
    "\n",
    "import numpy as np\n",
    "assert (s := files[\"prefix\"].value_counts().index.isin(useful_repo_names).sum()) == len(useful_repo_names), f\"{s} != {len(useful_repo_names)}\"\n",
    "\n",
    "cdt4py_repos = files[files[\"prefix\"].isin(useful_repo_names)]\n",
    "display(len(cdt4py_repos))\n",
    "display(cdt4py_repos[\"prefix\"].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f03fb765-3e37-4b3a-ab0a-ffb3b8d015d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "sized_groups = [group for _, group in cdt4py_repos.groupby(\"prefix\")]\n",
    "random.Random(42).shuffle(groups)\n",
    "\n",
    "cdt4py_shuffled_repos = pd.concat(groups).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5497d42d-6dee-4108-bc47-a1c448726ad0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prefix</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>numpy/marshall-lab/TITAN</td>\n",
       "      <td>tests/features/prep_test.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>numpy/JanAlexanderZak/leetspeak</td>\n",
       "      <td>tests/script.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>numpy/BMW-InnovationLab/BMW-YOLOv4-Training-Au...</td>\n",
       "      <td>src/exception_utils.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>numpy/BMW-InnovationLab/BMW-YOLOv4-Training-Au...</td>\n",
       "      <td>src/factory.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>numpy/BMW-InnovationLab/BMW-YOLOv4-Training-Au...</td>\n",
       "      <td>src/train.py</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prefix                         file\n",
       "0                           numpy/marshall-lab/TITAN  tests/features/prep_test.py\n",
       "1                    numpy/JanAlexanderZak/leetspeak              tests/script.py\n",
       "2  numpy/BMW-InnovationLab/BMW-YOLOv4-Training-Au...       src/exception_utils.py\n",
       "3  numpy/BMW-InnovationLab/BMW-YOLOv4-Training-Au...               src/factory.py\n",
       "4  numpy/BMW-InnovationLab/BMW-YOLOv4-Training-Au...                 src/train.py"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "26957"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prefix</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>numpy/marshall-lab/TITAN</td>\n",
       "      <td>tests/features/prep_test.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>numpy/JanAlexanderZak/leetspeak</td>\n",
       "      <td>tests/script.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>numpy/BMW-InnovationLab/BMW-YOLOv4-Training-Au...</td>\n",
       "      <td>src/exception_utils.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>numpy/BMW-InnovationLab/BMW-YOLOv4-Training-Au...</td>\n",
       "      <td>src/factory.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>numpy/BMW-InnovationLab/BMW-YOLOv4-Training-Au...</td>\n",
       "      <td>src/train.py</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prefix                         file\n",
       "0                           numpy/marshall-lab/TITAN  tests/features/prep_test.py\n",
       "1                    numpy/JanAlexanderZak/leetspeak              tests/script.py\n",
       "2  numpy/BMW-InnovationLab/BMW-YOLOv4-Training-Au...       src/exception_utils.py\n",
       "3  numpy/BMW-InnovationLab/BMW-YOLOv4-Training-Au...               src/factory.py\n",
       "4  numpy/BMW-InnovationLab/BMW-YOLOv4-Training-Au...                 src/train.py"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "21564"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prefix</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21564</th>\n",
       "      <td>numpy/taikiinoue45/STAD</td>\n",
       "      <td>stad/utils/show_test_results.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21565</th>\n",
       "      <td>numpy/taikiinoue45/STAD</td>\n",
       "      <td>streamboard/utils/show_test_anomaly_results.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21566</th>\n",
       "      <td>numpy/taikiinoue45/STAD</td>\n",
       "      <td>stad/datasets/mvtec.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21567</th>\n",
       "      <td>flask/VWS-Python/vws-python-mock</td>\n",
       "      <td>tests/mock_vws/fixtures/vuforia_backends.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21568</th>\n",
       "      <td>flask/VWS-Python/vws-python-mock</td>\n",
       "      <td>tests/mock_vws/test_target_list.py</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 prefix                                            file\n",
       "21564           numpy/taikiinoue45/STAD                 stad/utils/show_test_results.py\n",
       "21565           numpy/taikiinoue45/STAD  streamboard/utils/show_test_anomaly_results.py\n",
       "21566           numpy/taikiinoue45/STAD                          stad/datasets/mvtec.py\n",
       "21567  flask/VWS-Python/vws-python-mock     tests/mock_vws/fixtures/vuforia_backends.py\n",
       "21568  flask/VWS-Python/vws-python-mock              tests/mock_vws/test_target_list.py"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "5393"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "26957"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "weighted = cdt4py_shuffled_repos.groupby(\"prefix\", sort=False)\\\n",
    "  .agg({\"file\": \"count\"})\n",
    "weighted[\"file\"] = (weighted[\"file\"] / weighted[\"file\"].sum()).cumsum()\n",
    "#display(weighted[\"file\"].head())\n",
    "\n",
    "validation_repositories, test_repositories = weighted[weighted[\"file\"] < 0.8], weighted[weighted[\"file\"] >= 0.8]\n",
    "# display(validation_repositories, test_repositories)\n",
    "\n",
    "validation_split = cdt4py_shuffled_repos[cdt4py_shuffled_repos[\"prefix\"].isin(validation_repositories.index)]\n",
    "test_split = cdt4py_shuffled_repos[cdt4py_shuffled_repos[\"prefix\"].isin(test_repositories.index)]\n",
    "\n",
    "display(cdt4py_shuffled_repos.head(), total_files.shape[0])\n",
    "display(validation_split.head(), validation_split.shape[0])\n",
    "display(test_split.head(), test_split.shape[0])\n",
    "display(validation_split.shape[0] + test_split.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "c5ed6851-bb30-43e0-b930-7f6a70484dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== deduplicated ===\n",
      "project count: 1553\n",
      "file count: 26957\n",
      "file count stddev 30.7809954284995\n",
      "\n",
      "\n",
      "=== validation ===\n",
      "project count: 1256\n",
      "file count: 21564\n",
      "file count stddev 29.72779852642132\n",
      "\n",
      "\n",
      "=== test ===\n",
      "project count: 297\n",
      "file count: 5393\n",
      "file count stddev 34.92954115892228\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, split in zip((\"deduplicated\", \"validation\", \"test\"), (cdt4py_shuffled_repos, validation_split, test_split)):\n",
    "    print(\"===\", name, \"===\")\n",
    "    print(\"project count:\", split[\"prefix\"].nunique())\n",
    "    print(\"file count:\", split[\"file\"].count())\n",
    "    print(\"file count stddev\", split.groupby(\"prefix\").agg({\"file\": \"count\"})[\"file\"].std())\n",
    "    \n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "f14cc9cf-c552-4791-88ca-7a6e2e943391",
   "metadata": {},
   "outputs": [],
   "source": [
    "with (pathlib.Path(\"/nfs/data/students/bsparks/mdti4py-datasets-dedup\") / \"deduplicated.csv\").open(\"w\") as f:\n",
    "    cdt4py_shuffled_repos.to_csv(f, header=[\"project\", \"file\"], index=False)\n",
    "\n",
    "with (pathlib.Path(\"/nfs/data/students/bsparks/mdti4py-datasets-dedup\") / \"validation.csv\").open(\"w\") as f:\n",
    "    validation_split.to_csv(f, header=[\"project\", \"file\"], index=False)\n",
    "\n",
    "with (pathlib.Path(\"/nfs/data/students/bsparks/mdti4py-datasets-dedup\") / \"test.csv\").open(\"w\") as f:\n",
    "    test_split.to_csv(f, header=[\"project\", \"file\"], index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
